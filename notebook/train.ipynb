{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bzhvqhuvCknH",
      "metadata": {
        "id": "bzhvqhuvCknH"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "3yGCt_iVOTbf",
      "metadata": {
        "collapsed": true,
        "id": "3yGCt_iVOTbf"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fvij4u6oOS0O",
      "metadata": {
        "collapsed": true,
        "id": "Fvij4u6oOS0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q qwen_vl_utils decord librosa icecream hf_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "pE0krTTTOap4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pE0krTTTOap4",
        "outputId": "b2db1d25-3739-4d28-b37c-46bed029daec"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade --no-cache-dir ms-swift -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "PA8UcUZ231ky",
      "metadata": {
        "id": "PA8UcUZ231ky"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers==4.57.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3e369aee",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install deepspeed\n",
        "!pip install liger-kernel\n",
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_rhublm-YExe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rhublm-YExe",
        "outputId": "f771ee11-ece6-4470-abc5-d5a4dbc16e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: ms_swift\n",
            "Version: 3.10.3\n",
            "Summary: Swift: Scalable lightWeight Infrastructure for Fine-Tuning\n",
            "Home-page: https://github.com/modelscope/swift\n",
            "Author: DAMO ModelScope teams\n",
            "Author-email: contact@modelscope.cn\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: accelerate, addict, aiohttp, attrdict, binpacking, charset-normalizer, cpm-kernels, dacite, datasets, einops, fastapi, gradio, importlib-metadata, jieba, json-repair, matplotlib, modelscope, nltk, numpy, omegaconf, openai, oss2, pandas, peft, pillow, PyYAML, requests, rouge, safetensors, scipy, sentencepiece, simplejson, sortedcontainers, tensorboard, tiktoken, tqdm, transformers, transformers-stream-generator, trl, uvicorn, zstandard\n",
            "Required-by: synthetic-data\n",
            "Name: transformers\n",
            "Version: 4.57.0\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: ms_swift, peft, transformers-stream-generator, trl\n",
            "Name: flash_attn\n",
            "Version: 2.8.3\n",
            "Summary: Flash Attention: Fast and Memory-Efficient Exact Attention\n",
            "Home-page: https://github.com/Dao-AILab/flash-attention\n",
            "Author: Tri Dao\n",
            "Author-email: tri@tridao.me\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: einops, torch\n",
            "Required-by: \n",
            "Name: torch\n",
            "Version: 2.9.1\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org\n",
            "Author: \n",
            "Author-email: PyTorch Team <packages@pytorch.org>\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-cufile-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvshmem-cu12, nvidia-nvtx-cu12, setuptools, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, deepspeed, flash_attn, liger_kernel, peft, synthetic-data, torchaudio, torchvision\n"
          ]
        }
      ],
      "source": [
        "!pip show ms-swift\n",
        "!pip show transformers\n",
        "!pip show flash-attn\n",
        "!pip show torch\n",
        "!pip show deepspeed\n",
        "!pip show liger-kernel\n",
        "!pip show hf_transfer\n",
        "!pip show qwen_vl_utils\n",
        "!pip show decord\n",
        "!pip show librosa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DM6YDy5xCrPM",
      "metadata": {
        "id": "DM6YDy5xCrPM"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694307ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['HF_TOKEN'] = 'xxx'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V94pqTn9OBd6",
      "metadata": {
        "id": "V94pqTn9OBd6"
      },
      "source": [
        "#### **Hugging Face Hub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "IHxVGs4aNySr",
      "metadata": {
        "id": "IHxVGs4aNySr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "HF_TOKEN = os.environ['HF_TOKEN']\n",
        "login(token=HF_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uXWvkohn9emo",
      "metadata": {
        "id": "uXWvkohn9emo"
      },
      "source": [
        "#### **Clean Cache**\n",
        "\n",
        "Aqui podemos limpar caches que o huggingface criou de modelos carregados anteriormente. Documentação: [Clean your cache](https://huggingface.co/docs/huggingface_hub/v0.25.1/guides/manage-cache#clean-your-cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "pAqKMc_82kmp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAqKMc_82kmp",
        "outputId": "2d24d892-5db2-41b5-8eed-45742561c0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli scan-cache' is deprecated. Use 'hf cache scan' instead.\u001b[0m\n",
            "REPO ID                          REPO TYPE REVISION                                 SIZE ON DISK NB FILES LAST_MODIFIED  REFS LOCAL PATH                                                                                                                       \n",
            "-------------------------------- --------- ---------------------------------------- ------------ -------- -------------- ---- -------------------------------------------------------------------------------------------------------------------------------- \n",
            "samuellimabraz/quantum-assistant dataset   4dabf78de8927722a8ef828671320ecf02a775d5          0.0        0 29 seconds ago main /workspace/.cache/huggingface/hub/datasets--samuellimabraz--quantum-assistant/snapshots/4dabf78de8927722a8ef828671320ecf02a775d5 \n",
            "\n",
            "Done in 0.0s. Scanned 1 repo(s) for a total of \u001b[1m\u001b[31m0.0\u001b[0m.\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli scan-cache -vvv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "EhXzeHPtD1a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhXzeHPtD1a8",
        "outputId": "466ea8e2-94af-48d0-8977-30446ef8c32a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scan_cache_dir' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscan_cache_dir\u001b[49m().size_on_disk)\n",
            "\u001b[31mNameError\u001b[39m: name 'scan_cache_dir' is not defined"
          ]
        }
      ],
      "source": [
        "print(scan_cache_dir().size_on_disk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8sNEulLWw6Dm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sNEulLWw6Dm",
        "outputId": "b4c545b6-7a29-4121-941d-faad79017a58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will free 4.4G\n"
          ]
        }
      ],
      "source": [
        "delete_strategy = scan_cache_dir().delete_revisions(\n",
        "    \"512088035485789edb42511739e85060eafd1551\",\n",
        ")\n",
        "print(\"Will free \" + delete_strategy.expected_freed_size_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NNyPkvu6w9O9",
      "metadata": {
        "id": "NNyPkvu6w9O9"
      },
      "outputs": [],
      "source": [
        "delete_strategy.execute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dzuvZ7rhOqPS",
      "metadata": {
        "id": "dzuvZ7rhOqPS"
      },
      "outputs": [],
      "source": [
        "from transformers import TRANSFORMERS_CACHE\n",
        "import shutil\n",
        "\n",
        "def clean_transformers_cache():\n",
        "    \"\"\"Clean the contents of the transformers cache while keeping the root directory.\"\"\"\n",
        "    # List all files and directories in the TRANSFORMERS_CACHE directory\n",
        "    for item in os.listdir(TRANSFORMERS_CACHE):\n",
        "        item_path = os.path.join(TRANSFORMERS_CACHE, item)\n",
        "        # Check if it's a directory or file and remove accordingly\n",
        "        if os.path.isdir(item_path):\n",
        "            shutil.rmtree(item_path)\n",
        "        elif os.path.isfile(item_path):\n",
        "            os.remove(item_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qjVzSyeT3nmO",
      "metadata": {
        "id": "qjVzSyeT3nmO"
      },
      "source": [
        "#### Free Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VLhS1pKQ3po1",
      "metadata": {
        "id": "VLhS1pKQ3po1"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "import time\n",
        "\n",
        "def flush():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  torch.cuda.reset_peak_memory_stats()\n",
        "  for _ in range(10):\n",
        "        gc.collect()\n",
        "        with torch.no_grad():\n",
        "          torch.cuda.empty_cache()\n",
        "        time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W4j7BS4_N8tI",
      "metadata": {
        "id": "W4j7BS4_N8tI"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8935af4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8935af4f",
        "outputId": "c6b79f05-a859-4fe4-f864-dfbaac28265e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec  7 22:30:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA RTX PRO 6000 Blac...    On  |   00000000:E1:00.0 Off |                    0 |\n",
            "| N/A   31C    P0             98W /  600W |       0MiB /  97887MiB |    100%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614ae2f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/quantum-assistant\n"
          ]
        }
      ],
      "source": [
        "%cd ~/quantum-assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45af95be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LICENSE    assets  docs      pyproject.toml    scripts\t src\tuv.lock\n",
            "README.md  docker  notebook  requirements.txt  setup.py  tests\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487be3ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "487be3ea",
        "outputId": "3d26a963-bcbd-4b18-93c1-1ad8e5e275f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering content: 100% (22/22)\rFiltering content: 100% (22/22), 2.44 MiB | 2.39 MiB/s, done.\n",
            "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
            "Switched to a new branch 'dev'\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git switch dev\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R-zozEu-Tj9m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R-zozEu-Tj9m",
        "outputId": "96ae069e-1f86-4812-b965-0eb06b7587b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///root/quantum-assistant\n",
            "  Installing build dependencies ... \u001b[?25l"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n",
            "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (2.12.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: nbformat>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (5.10.4)\n",
            "Requirement already satisfied: pillow>=10.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (11.0.0)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: typer>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (0.20.0)\n",
            "Requirement already satisfied: rich>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (14.2.0)\n",
            "Collecting pymupdf>=1.23.0 (from synthetic-data==0.1.0)\n",
            "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-dotenv>=1.0.0 (from synthetic-data==0.1.0)\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting qiskit>=2.2.3 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit-2.2.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy>=1.15.3 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (1.16.3)\n",
            "Collecting pytest>=9.0.0 (from synthetic-data==0.1.0)\n",
            "  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting wand>=0.6.13 (from synthetic-data==0.1.0)\n",
            "  Downloading Wand-0.6.13-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pip>=25.3 (from synthetic-data==0.1.0)\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting qiskit-machine-learning>=0.8.2 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting qiskit-ibm-runtime>=0.43.1 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_ibm_runtime-0.43.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting qiskit-aer>=0.17.2 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_aer-0.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting torch>=2.9.1 (from synthetic-data==0.1.0)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting qiskit-addon-sqd>=0.12.0 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_sqd-0.12.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting qiskit-addon-pna>=0.2.0 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_pna-0.2.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting qiskit-addon-slc>=0.1.0 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_slc-0.1.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting qiskit-addon-utils>=0.3.0 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_utils-0.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting samplomatic>=0.13.0 (from synthetic-data==0.1.0)\n",
            "  Downloading samplomatic-0.13.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting mthree>=3.0.0 (from synthetic-data==0.1.0)\n",
            "  Downloading mthree-3.0.0-cp312-cp312-manylinux_2_34_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting rustworkx>=0.17.1 (from synthetic-data==0.1.0)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting imbalanced-learn>=0.14.0 (from synthetic-data==0.1.0)\n",
            "  Downloading imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting qiskit-addon-obp>=0.3.0 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_obp-0.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gem-suite>=0.1.6 (from synthetic-data==0.1.0)\n",
            "  Downloading gem_suite-0.1.6-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (539 bytes)\n",
            "Collecting qiskit-addon-mpf>=0.3.0 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_mpf-0.3.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting quimb>=1.11.2 (from synthetic-data==0.1.0)\n",
            "  Downloading quimb-1.11.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting qiskit-quimb>=0.0.9 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_quimb-0.0.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting yfinance>=0.2.66 (from synthetic-data==0.1.0)\n",
            "  Downloading yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting qiskit-ibm-transpiler>=0.13.1 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_ibm_transpiler-0.15.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting qiskit-addon-aqc-tensor>=0.2.0 (from qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading qiskit_addon_aqc_tensor-0.2.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pysat>=3.2.2 (from synthetic-data==0.1.0)\n",
            "  Downloading pysat-3.2.2.tar.gz (419 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting python-sat>=1.8.dev24 (from synthetic-data==0.1.0)\n",
            "  Downloading python_sat-1.8.dev24-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: ms-swift>=3.10.3 in /usr/local/lib/python3.12/dist-packages (from synthetic-data==0.1.0) (3.10.3)\n",
            "Collecting plotly>=6.5.0 (from synthetic-data==0.1.0)\n",
            "  Downloading plotly-6.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting kaleido>=1.2.0 (from synthetic-data==0.1.0)\n",
            "  Downloading kaleido-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (22.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (2.32.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->synthetic-data==0.1.0) (25.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (3.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->synthetic-data==0.1.0) (4.15.0)\n",
            "Collecting pymatching (from gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading pymatching-2.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n",
            "Collecting qiskit-experiments>=0.7 (from gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading qiskit_experiments-0.13.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->synthetic-data==0.1.0) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->synthetic-data==0.1.0) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->synthetic-data==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->synthetic-data==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.16.0->synthetic-data==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn>=0.14.0->synthetic-data==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn>=0.14.0->synthetic-data==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn>=0.14.0->synthetic-data==0.1.0) (3.6.0)\n",
            "Collecting choreographer>=1.1.1 (from kaleido>=1.2.0->synthetic-data==0.1.0)\n",
            "  Downloading choreographer-1.2.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting logistro>=1.0.8 (from kaleido>=1.2.0->synthetic-data==0.1.0)\n",
            "  Downloading logistro-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from kaleido>=1.2.0->synthetic-data==0.1.0) (3.11.5)\n",
            "Collecting pytest-timeout>=2.4.0 (from kaleido>=1.2.0->synthetic-data==0.1.0)\n",
            "  Downloading pytest_timeout-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.1.1->kaleido>=1.2.0->synthetic-data==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (1.12.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: binpacking in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: cpm-kernels in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (1.0.11)\n",
            "Requirement already satisfied: dacite in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (1.9.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.124.0)\n",
            "Requirement already satisfied: gradio>=3.40.0 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (8.7.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.42.1)\n",
            "Requirement already satisfied: json-repair in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.54.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (3.10.7)\n",
            "Requirement already satisfied: modelscope>=1.23 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (1.32.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (3.9.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.9.0)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.19.1)\n",
            "Requirement already satisfied: peft<0.18,>=0.11 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.17.1)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (2.20.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.12.0)\n",
            "Requirement already satisfied: transformers<4.58,>=4.33 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (4.57.0)\n",
            "Requirement already satisfied: transformers-stream-generator in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.0.5)\n",
            "Requirement already satisfied: trl<0.25,>=0.15 in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.24.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.38.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.12/dist-packages (from ms-swift>=3.10.3->synthetic-data==0.1.0) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft<0.18,>=0.11->ms-swift>=3.10.3->synthetic-data==0.1.0) (7.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58,>=4.33->ms-swift>=3.10.3->synthetic-data==0.1.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58,>=4.33->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.22.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.0.20)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.40.0->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->synthetic-data==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->synthetic-data==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->synthetic-data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->synthetic-data==0.1.0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->synthetic-data==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->synthetic-data==0.1.0) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->synthetic-data==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.0->synthetic-data==0.1.0) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.0->synthetic-data==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.23->ms-swift>=3.10.3->synthetic-data==0.1.0) (80.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.23->ms-swift>=3.10.3->synthetic-data==0.1.0) (2.5.0)\n",
            "Collecting cython>=3.0.10 (from mthree>=3.0.0->synthetic-data==0.1.0)\n",
            "  Downloading cython-3.2.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting runningman>=2.1 (from mthree>=3.0.0->synthetic-data==0.1.0)\n",
            "  Downloading runningman-2.3.0.tar.gz (15 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.9.0->synthetic-data==0.1.0) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.9.0->synthetic-data==0.1.0) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.9.0->synthetic-data==0.1.0) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.9.0->synthetic-data==0.1.0) (5.14.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.9.0->synthetic-data==0.1.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.9.0->synthetic-data==0.1.0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.9.0->synthetic-data==0.1.0) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.9.0->synthetic-data==0.1.0) (4.5.0)\n",
            "Collecting narwhals>=1.15.1 (from plotly>=6.5.0->synthetic-data==0.1.0)\n",
            "  Downloading narwhals-2.13.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dask (from pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading dask-2025.11.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting netCDF4 (from pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting portalocker (from pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting toolz (from pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting xarray>=0.16.2 (from pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading xarray-2025.12.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting iniconfig>=1.0.1 (from pytest>=9.0.0->synthetic-data==0.1.0)\n",
            "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pluggy<2,>=1.5 (from pytest>=9.0.0->synthetic-data==0.1.0)\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=9.0.0->synthetic-data==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->synthetic-data==0.1.0) (1.16.0)\n",
            "Collecting stevedore>=3.0.0 (from qiskit>=2.2.3->synthetic-data==0.1.0)\n",
            "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting plum-dispatch>=2.4.1 (from qiskit-addon-aqc-tensor>=0.2.0->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading plum_dispatch-2.6.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting wrapt>=1.13.3 (from qiskit-addon-aqc-tensor>=0.2.0->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting beartype>=0.16.2 (from plum-dispatch>=2.4.1->qiskit-addon-aqc-tensor>=0.2.0->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading beartype-0.22.8-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jax>=0.4.30 (from qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting kahypar>=1.3.5 (from qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading kahypar-1.3.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.12/dist-packages (from qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0) (3.3)\n",
            "Collecting autoray>=0.6.12 (from quimb>=1.11.2->synthetic-data==0.1.0)\n",
            "  Downloading autoray-0.8.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting cotengra>=0.7.1 (from quimb>=1.11.2->synthetic-data==0.1.0)\n",
            "  Downloading cotengra-0.7.5-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting cytoolz>=0.8.0 (from quimb>=1.11.2->synthetic-data==0.1.0)\n",
            "  Downloading cytoolz-1.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numba>=0.39 in /usr/local/lib/python3.12/dist-packages (from quimb>=1.11.2->synthetic-data==0.1.0) (0.62.1)\n",
            "Collecting jaxlib<=0.8.1,>=0.8.1 (from jax>=0.4.30->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.4.30->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting opt_einsum (from jax>=0.4.30->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.39->quimb>=1.11.2->synthetic-data==0.1.0) (0.45.1)\n",
            "Collecting cvxpy>=1.6 (from qiskit-addon-mpf>=0.3.0->synthetic-data==0.1.0)\n",
            "  Downloading cvxpy-1.7.5-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting osqp>=1.0.0 (from cvxpy>=1.6->qiskit-addon-mpf>=0.3.0->synthetic-data==0.1.0)\n",
            "  Downloading osqp-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting clarabel>=0.5.0 (from cvxpy>=1.6->qiskit-addon-mpf>=0.3.0->synthetic-data==0.1.0)\n",
            "  Downloading clarabel-0.11.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting scs>=3.2.4.post1 (from cvxpy>=1.6->qiskit-addon-mpf>=0.3.0->synthetic-data==0.1.0)\n",
            "  Downloading scs-3.2.9-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from clarabel>=0.5.0->cvxpy>=1.6->qiskit-addon-mpf>=0.3.0->synthetic-data==0.1.0) (2.0.0)\n",
            "Collecting pauli-prop (from qiskit-addon-pna>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading pauli_prop-0.1.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pyscf<3,>=2.10 (from qiskit-addon-slc>=0.1.0->synthetic-data==0.1.0)\n",
            "  Downloading pyscf-2.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->ms-swift>=3.10.3->synthetic-data==0.1.0) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3/dist-packages (from matplotlib->ms-swift>=3.10.3->synthetic-data==0.1.0) (3.1.1)\n",
            "Collecting h5py>=2.7 (from pyscf<3,>=2.10->qiskit-addon-slc>=0.1.0->synthetic-data==0.1.0)\n",
            "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting qiskit-ibm-experiment>=0.4.6 (from qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading qiskit_ibm_experiment-0.4.8-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting uncertainties (from qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading uncertainties-3.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting lmfit (from qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading lmfit-1.3.4-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-experiment>=0.4.6->qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: websocket-client>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from qiskit-ibm-experiment>=0.4.6->qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0) (1.9.0)\n",
            "Collecting ibm-platform-services>=0.22.6 (from qiskit-ibm-runtime>=0.43.1->synthetic-data==0.1.0)\n",
            "  Downloading ibm_platform_services-0.71.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting ibm_cloud_sdk_core<4.0.0,>=3.24.2 (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime>=0.43.1->synthetic-data==0.1.0)\n",
            "  Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting PyJWT<3.0.0,>=2.10.1 (from ibm_cloud_sdk_core<4.0.0,>=3.24.2->ibm-platform-services>=0.22.6->qiskit-ibm-runtime>=0.43.1->synthetic-data==0.1.0)\n",
            "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting backoff~=2.0 (from qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting qiskit-qasm3-import~=0.4 (from qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading qiskit_qasm3_import-0.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting networkx>=2.3 (from qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading networkx-2.8.5-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting qiskit-serverless~=0.27.0 (from qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading qiskit_serverless-0.27.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting qiskit_ibm_ai_local_transpiler~=0.5 (from qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading qiskit_ibm_ai_local_transpiler-0.5.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting openqasm3<2.0,>=0.4 (from openqasm3[parser]<2.0,>=0.4->qiskit-qasm3-import~=0.4->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading openqasm3-1.0.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: antlr4_python3_runtime<4.14,>=4.7 in /usr/local/lib/python3.12/dist-packages (from openqasm3[parser]<2.0,>=0.4->qiskit-qasm3-import~=0.4->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (4.9.3)\n",
            "Collecting ray<3,>=2.30 (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting cloudpickle==2.2.1 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting opentelemetry-api<1.33.1,>=1.18.0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-sdk<1.33.1,>=1.18.0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc<1.33.1,>=1.18.0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.60b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: ipywidgets<9,>=8.1.6 in /usr/local/lib/python3.12/dist-packages (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (8.1.7)\n",
            "Collecting ipython<9,>=8.10.0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading ipython-8.37.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->synthetic-data==0.1.0)\n",
            "  Downloading pyarrow-18.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting zipp==3.19.1 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading zipp-3.19.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting certifi (from httpx>=0.27.0->synthetic-data==0.1.0)\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting importlib-metadata (from ms-swift>=3.10.3->synthetic-data==0.1.0)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading importlib_metadata-8.6.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (5.2.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (3.0.52)\n",
            "Requirement already satisfied: stack_data in /usr/local/lib/python3.12/dist-packages (from ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.6.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=8.1.6->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.2.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=8.1.6->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=8.1.6->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (3.0.15)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (1.76.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.33.0->opentelemetry-exporter-otlp-proto-grpc<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.54b0 (from opentelemetry-sdk<1.33.1,>=1.18.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.2.14)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit[qpy-compat]<3,>=1.4->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: sympy>1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit[qpy-compat]<3,>=1.4->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (1.13.3)\n",
            "Collecting click>=8.0.0 (from typer>=0.12.0->synthetic-data==0.1.0)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<3,>=2.30->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (1.1.2)\n",
            "Collecting aiohttp_cors (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Collecting opencensus (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.23.1)\n",
            "Collecting smart_open (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.12/dist-packages (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (20.34.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.8.5)\n",
            "Collecting opentelemetry-instrumentation==0.60b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.58b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "INFO: pip is still looking at multiple versions of opentelemetry-instrumentation-requests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation-requests>=0.40b0 (from qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-requests>=0.40b0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wrapt>=1.13.3 (from qiskit-addon-aqc-tensor>=0.2.0->qiskit-addon-aqc-tensor[aer,quimb-jax]>=0.2.0->synthetic-data==0.1.0)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.7.0)\n",
            "INFO: pip is looking at multiple versions of qiskit-machine-learning to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting qiskit-machine-learning>=0.8.2 (from synthetic-data==0.1.0)\n",
            "  Downloading qiskit_machine_learning-0.8.3-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading qiskit_machine_learning-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/lib/python3/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-experiment>=0.4.6->qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0) (41.0.7)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-experiment>=0.4.6->qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading pyspnego-0.12.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.0.0->synthetic-data==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.0.0->synthetic-data==0.1.0) (0.1.2)\n",
            "Collecting pybase64>=1.4.0 (from samplomatic>=0.13.0->synthetic-data==0.1.0)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>1.3->qiskit[qpy-compat]<3,>=1.4->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.9.1->synthetic-data==0.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.9.1->synthetic-data==0.1.0)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.9.1->synthetic-data==0.1.0) (1.13.1.3)\n",
            "Collecting triton==3.5.1 (from torch>=2.9.1->synthetic-data==0.1.0)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.4.0)\n",
            "Collecting multitasking>=0.0.7 (from yfinance>=0.2.66->synthetic-data==0.1.0)\n",
            "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting frozendict>=2.3.4 (from yfinance>=0.2.66->synthetic-data==0.1.0)\n",
            "  Downloading frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance>=0.2.66->synthetic-data==0.1.0)\n",
            "  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance>=0.2.66->synthetic-data==0.1.0) (4.14.2)\n",
            "Collecting curl_cffi>=0.7 (from yfinance>=0.2.66->synthetic-data==0.1.0)\n",
            "  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting websockets>=13.0 (from yfinance>=0.2.66->synthetic-data==0.1.0)\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance>=0.2.66->synthetic-data==0.1.0) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.6->qiskit-addon-mpf>=0.3.0->synthetic-data==0.1.0) (2.23)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from binpacking->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.0.0)\n",
            "INFO: pip is looking at multiple versions of dask to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dask (from pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading dask-2025.10.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.9.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.7.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.5.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.4.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of dask to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask-2025.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2025.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading dask-2024.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.11.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.11.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.8.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading dask-2024.8.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading dask-2024.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting partd>=1.4.0 (from dask->pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting locket (from partd>=1.4.0->dask->pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting asteval>=1.0 (from lmfit->qiskit-experiments>=0.7->gem-suite>=0.1.6->synthetic-data==0.1.0)\n",
            "  Downloading asteval-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting cftime (from netCDF4->pysat>=3.2.2->synthetic-data==0.1.0)\n",
            "  Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.12.0)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-exporter-prometheus to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default]<3,>=2.30->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.57b0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.56b0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.55b1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.55b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.54b1-py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: pip is still looking at multiple versions of opentelemetry-exporter-prometheus to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading opentelemetry_exporter_prometheus-0.54b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.12/dist-packages (from oss2->ms-swift>=3.10.3->synthetic-data==0.1.0) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.12/dist-packages (from oss2->ms-swift>=3.10.3->synthetic-data==0.1.0) (3.23.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from oss2->ms-swift>=3.10.3->synthetic-data==0.1.0) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.12/dist-packages (from oss2->ms-swift>=3.10.3->synthetic-data==0.1.0) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from stack_data->ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from stack_data->ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.12/dist-packages (from stack_data->ipython<9,>=8.10.0->qiskit-serverless~=0.27.0->qiskit-ibm-transpiler>=0.13.1->synthetic-data==0.1.0) (0.2.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->ms-swift>=3.10.3->synthetic-data==0.1.0) (2.3.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->ms-swift>=3.10.3->synthetic-data==0.1.0) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->ms-swift>=3.10.3->synthetic-data==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->ms-swift>=3.10.3->synthetic-data==0.1.0) (3.1.4)\n",
            "Downloading gem_suite-0.1.6-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (699 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.8/699.8 kB\u001b[0m \u001b[31m139.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
            "Downloading kaleido-1.2.0-py3-none-any.whl (68 kB)\n",
            "Downloading choreographer-1.2.1-py3-none-any.whl (49 kB)\n",
            "Downloading logistro-2.0.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading mthree-3.0.0-cp312-cp312-manylinux_2_34_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading cython-3.2.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "Downloading plotly-6.5.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-2.13.0-py3-none-any.whl (426 kB)\n",
            "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-9.0.2-py3-none-any.whl (374 kB)\n",
            "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading pytest_timeout-2.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading python_sat-1.8.dev24-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-2.2.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_addon_aqc_tensor-0.2.0-py3-none-any.whl (40 kB)\n",
            "Downloading plum_dispatch-2.6.0-py3-none-any.whl (42 kB)\n",
            "Downloading beartype-0.22.8-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m256.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_quimb-0.0.9-py3-none-any.whl (8.8 kB)\n",
            "Downloading quimb-1.11.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m181.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.4-py3-none-any.whl (937 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m937.5/937.5 kB\u001b[0m \u001b[31m143.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cotengra-0.7.5-py3-none-any.whl (195 kB)\n",
            "Downloading cytoolz-1.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m193.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.8.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m203.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl (80.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading kahypar-1.3.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m151.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_addon_mpf-0.3.0-py3-none-any.whl (68 kB)\n",
            "Downloading cvxpy-1.7.5-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m168.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clarabel-0.11.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m252.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading osqp-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (357 kB)\n",
            "Downloading qiskit_addon_obp-0.3.0-py3-none-any.whl (30 kB)\n",
            "Downloading qiskit_addon_pna-0.2.0-py3-none-any.whl (20 kB)\n",
            "Downloading qiskit_addon_slc-0.1.0-py3-none-any.whl (50 kB)\n",
            "Downloading pauli_prop-0.1.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (340 kB)\n",
            "Downloading pyscf-2.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_addon_sqd-0.12.0-py3-none-any.whl (35 kB)\n",
            "Downloading qiskit_addon_utils-0.3.0-py3-none-any.whl (58 kB)\n",
            "Downloading qiskit_aer-0.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_experiments-0.13.0-py3-none-any.whl (629 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m629.3/629.3 kB\u001b[0m \u001b[31m139.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_ibm_experiment-0.4.8-py3-none-any.whl (57 kB)\n",
            "Downloading qiskit_ibm_runtime-0.43.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m174.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ibm_platform_services-0.71.0-py3-none-any.whl (377 kB)\n",
            "Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl (75 kB)\n",
            "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Downloading qiskit_ibm_transpiler-0.15.0-py3-none-any.whl (47 kB)\n",
            "Downloading networkx-2.8.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m157.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading qiskit_ibm_ai_local_transpiler-0.5.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (97.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_qasm3_import-0.6.0-py3-none-any.whl (29 kB)\n",
            "Downloading openqasm3-1.0.1-py3-none-any.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.5/541.5 kB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_serverless-0.27.1-py3-none-any.whl (57 kB)\n",
            "Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading zipp-3.19.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading ipython-8.37.0-py3-none-any.whl (831 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.9/831.9 kB\u001b[0m \u001b[31m191.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.33.0-py3-none-any.whl (65 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.33.0-py3-none-any.whl (55 kB)\n",
            "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl (194 kB)\n",
            "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Downloading pyarrow-18.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:13\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation_requests-0.54b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_machine_learning-0.8.2-py3-none-any.whl (231 kB)\n",
            "Downloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading pyspnego-0.12.0-py3-none-any.whl (130 kB)\n",
            "Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading samplomatic-0.13.0-py3-none-any.whl (180 kB)\n",
            "Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "Downloading scs-3.2.9-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
            "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
            "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m142.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m186.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m229.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading Wand-0.6.13-py2.py3-none-any.whl (143 kB)\n",
            "Downloading xarray-2025.12.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m155.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
            "Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
            "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\n",
            "Downloading dask-2024.8.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m294.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading lmfit-1.3.4-py3-none-any.whl (97 kB)\n",
            "Downloading asteval-1.0.7-py3-none-any.whl (22 kB)\n",
            "Downloading uncertainties-3.2.3-py3-none-any.whl (60 kB)\n",
            "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m195.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
            "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading opentelemetry_exporter_prometheus-0.54b0-py3-none-any.whl (12 kB)\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading pymatching-2.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.1/626.1 kB\u001b[0m \u001b[31m141.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
            "Building wheels for collected packages: synthetic-data, pysat, runningman, multitasking, peewee\n",
            "  Building editable for synthetic-data (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for synthetic-data: filename=synthetic_data-0.1.0-0.editable-py3-none-any.whl size=6323 sha256=209a72f3507fb1811f2a552c8cb79304234b622913693b66783e8eb063812c2c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-knu7adi5/wheels/50/2e/14/65e63a720c46cdaf4866cf37f895d2f615a38b989a100fea1e\n",
            "  Building wheel for pysat (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pysat: filename=pysat-3.2.2-py3-none-any.whl size=434052 sha256=331df78be3a9b4bb1b9b4451a60e7f8bbd76fe7be8a14d16e9f671df3fb5c10a\n",
            "  Stored in directory: /workspace/.cache/pip/wheels/19/44/93/10c576d941d3219592f2f4b24ff6bcf6405213913784393d29\n",
            "  Building wheel for runningman (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for runningman: filename=runningman-2.3.0-py3-none-any.whl size=20722 sha256=2fc0526609d97c8f0b49b4d0b12e05cdfd4c879236f759c1864d8e405693a7ff\n",
            "  Stored in directory: /workspace/.cache/pip/wheels/fe/e2/f9/d0b64e05745dbd68c6746279e5a551afd211820c4bb48da48b\n",
            "  Building wheel for multitasking (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15636 sha256=97d1f0a0f89058f0e23936fa762c80b938720bf2db37ce3f793ee5510907c700\n",
            "  Stored in directory: /workspace/.cache/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for peewee: filename=peewee-3.18.3-py3-none-any.whl size=139133 sha256=573c0c6e2027f58c9b7aa976f949cfa1be11e4762c2b833f05e3db2d56b66fc1\n",
            "  Stored in directory: /workspace/.cache/pip/wheels/e2/48/b6/675a31c56e50b8b343e1ffbb1d9209f0d95025e2cfa0bbeeed\n",
            "Successfully built synthetic-data pysat runningman multitasking peewee\n",
            "Installing collected packages: wand, py-spy, peewee, openqasm3, opencensus-context, multitasking, kahypar, colorful, zipp, wrapt, websockets, uncertainties, triton, toolz, symengine, stevedore, rustworkx, python-sat, python-dotenv, pyspnego, pymupdf, PyJWT, pybase64, pyasn1, pyarrow, protobuf, portalocker, pluggy, pip, opt_einsum, opentelemetry-util-http, nvidia-nvshmem-cu12, nvidia-nccl-cu12, networkx, narwhals, ml_dtypes, logistro, locket, iniconfig, h5py, frozendict, cython, cloudpickle, click, cftime, certifi, cachetools, beartype, backoff, autoray, asteval, smart_open, scs, rsa, qiskit, pytest, pyscf, pyasn1-modules, proto-plus, plotly, partd, osqp, opentelemetry-proto, netCDF4, lmfit, jaxlib, ipython, importlib-metadata, googleapis-common-protos, deprecated, cytoolz, curl_cffi, cotengra, clarabel, choreographer, yfinance, xarray, torch, samplomatic, requests-ntlm, quimb, qiskit-qasm3-import, qiskit-machine-learning, qiskit-aer, qiskit-addon-utils, pytest-timeout, pymatching, plum-dispatch, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jax, imbalanced-learn, ibm_cloud_sdk_core, google-auth, dask, cvxpy, aiohttp_cors, ray, qiskit-quimb, qiskit-ibm-experiment, qiskit-addon-sqd, qiskit-addon-mpf, qiskit-addon-aqc-tensor, pysat, pauli-prop, opentelemetry-semantic-conventions, kaleido, ibm-platform-services, google-api-core, qiskit-ibm-runtime, qiskit-addon-slc, qiskit-addon-pna, opentelemetry-sdk, opentelemetry-instrumentation, opencensus, runningman, qiskit_ibm_ai_local_transpiler, qiskit-experiments, qiskit-addon-obp, opentelemetry-instrumentation-requests, opentelemetry-exporter-prometheus, opentelemetry-exporter-otlp-proto-grpc, mthree, gem-suite, qiskit-serverless, qiskit-ibm-transpiler, synthetic-data\n",
            "\u001b[2K  Attempting uninstall: zipp━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K    Found existing installation: zipp 3.23.0━━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K    Uninstalling zipp-3.23.0:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K      Successfully uninstalled zipp-3.23.0━━━━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K    Found existing installation: triton 3.4.0━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K    Uninstalling triton-3.4.0:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  3/127\u001b[0m [openqasm3]\n",
            "\u001b[2K      Successfully uninstalled triton-3.4.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/127\u001b[0m [triton]\n",
            "\u001b[2K  Attempting uninstall: PyJWT[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]otenv]\n",
            "\u001b[2K    Found existing installation: PyJWT 2.7.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K    Uninstalling PyJWT-2.7.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K      Successfully uninstalled PyJWT-2.7.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K  Attempting uninstall: pyarrow━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K    Found existing installation: pyarrow 22.0.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K    Uninstalling pyarrow-22.0.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K      Successfully uninstalled pyarrow-22.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/127\u001b[0m [pymupdf]\n",
            "\u001b[2K  Attempting uninstall: protobuf0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/127\u001b[0m [pyarrow]\n",
            "\u001b[2K    Found existing installation: protobuf 6.33.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/127\u001b[0m [pyarrow]\n",
            "\u001b[2K    Uninstalling protobuf-6.33.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/127\u001b[0m [pyarrow]\n",
            "\u001b[2K      Successfully uninstalled protobuf-6.33.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/127\u001b[0m [pyarrow]\n",
            "\u001b[2K  Attempting uninstall: pip0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/127\u001b[0m [protobuf]\n",
            "\u001b[2K    Found existing installation: pip 25.2━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/127\u001b[0m [protobuf]\n",
            "\u001b[2K    Uninstalling pip-25.2:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/127\u001b[0m [protobuf]\n",
            "\u001b[2K      Successfully uninstalled pip-25.2━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/127\u001b[0m [protobuf]\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 31/127\u001b[0m [nvidia-nvshmem-cu12]\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3━━━━━━\u001b[0m \u001b[32m 31/127\u001b[0m [nvidia-nvshmem-cu12]\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 31/127\u001b[0m [nvidia-nvshmem-cu12]\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3━━━━━━━━\u001b[0m \u001b[32m 31/127\u001b[0m [nvidia-nvshmem-cu12]\n",
            "\u001b[2K  Attempting uninstall: networkx\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 32/127\u001b[0m [nvidia-nccl-cu12]\n",
            "\u001b[2K    Found existing installation: networkx 3.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 32/127\u001b[0m [nvidia-nccl-cu12]\n",
            "\u001b[2K    Uninstalling networkx-3.3:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 32/127\u001b[0m [nvidia-nccl-cu12]\n",
            "\u001b[2K      Successfully uninstalled networkx-3.3━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 33/127\u001b[0m [networkx]u12]\n",
            "\u001b[2K  Attempting uninstall: click╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/127\u001b[0m [cython]es]\n",
            "\u001b[2K    Found existing installation: click 8.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/127\u001b[0m [cython]\n",
            "\u001b[2K    Uninstalling click-8.3.1:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/127\u001b[0m [cython]\n",
            "\u001b[2K      Successfully uninstalled click-8.3.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 41/127\u001b[0m [cython]\n",
            "\u001b[2K  Attempting uninstall: certifi\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/127\u001b[0m [click]\n",
            "\u001b[2K    Found existing installation: certifi 2025.10.5━━━━━━━━━━━━\u001b[0m \u001b[32m 43/127\u001b[0m [click]\n",
            "\u001b[2K    Uninstalling certifi-2025.10.5:m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/127\u001b[0m [click]\n",
            "\u001b[2K      Successfully uninstalled certifi-2025.10.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/127\u001b[0m [click]\n",
            "\u001b[2K  Attempting uninstall: ipythonm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 65/127\u001b[0m [jaxlib]modules]\n",
            "\u001b[2K    Found existing installation: ipython 9.6.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 65/127\u001b[0m [jaxlib]\n",
            "\u001b[2K    Uninstalling ipython-9.6.0:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 65/127\u001b[0m [jaxlib]\n",
            "\u001b[2K      Successfully uninstalled ipython-9.6.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 65/127\u001b[0m [jaxlib]\n",
            "\u001b[2K  Attempting uninstall: importlib-metadata\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 66/127\u001b[0m [ipython]\n",
            "\u001b[2K    Found existing installation: importlib_metadata 8.7.0━━━━━\u001b[0m \u001b[32m 66/127\u001b[0m [ipython]\n",
            "\u001b[2K    Uninstalling importlib_metadata-8.7.0:m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 66/127\u001b[0m [ipython]\n",
            "\u001b[2K      Successfully uninstalled importlib_metadata-8.7.0━━━━━━━\u001b[0m \u001b[32m 66/127\u001b[0m [ipython]\n",
            "\u001b[2K  Attempting uninstall: torch━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 76/127\u001b[0m [xarray]fi]\n",
            "\u001b[2K    Found existing installation: torch 2.8.0+cu128━━━━━━━━━━━━\u001b[0m \u001b[32m 76/127\u001b[0m [xarray]\n",
            "\u001b[2K    Uninstalling torch-2.8.0+cu128:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/127\u001b[0m [torch]\n",
            "\u001b[2K      Successfully uninstalled torch-2.8.0+cu12890m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 77/127\u001b[0m [torch]\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127/127\u001b[0m [synthetic-data]m [qiskit-experiments]nspiler]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu128 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\n",
            "torchvision 0.23.0+cu128 requires torch==2.8.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyJWT-2.10.1 aiohttp_cors-0.8.1 asteval-1.0.7 autoray-0.8.4 backoff-2.2.1 beartype-0.22.8 cachetools-6.2.2 certifi-2024.7.4 cftime-1.6.5 choreographer-1.2.1 clarabel-0.11.1 click-8.2.1 cloudpickle-2.2.1 colorful-0.5.8 cotengra-0.7.5 curl_cffi-0.13.0 cvxpy-1.7.5 cython-3.2.2 cytoolz-1.1.0 dask-2024.8.0 deprecated-1.3.1 frozendict-2.4.7 gem-suite-0.1.6 google-api-core-2.28.1 google-auth-2.43.0 googleapis-common-protos-1.72.0 h5py-3.15.1 ibm-platform-services-0.71.0 ibm_cloud_sdk_core-3.24.2 imbalanced-learn-0.14.0 importlib-metadata-8.4.0 iniconfig-2.3.0 ipython-8.37.0 jax-0.8.1 jaxlib-0.8.1 kahypar-1.3.5 kaleido-1.2.0 lmfit-1.3.4 locket-1.0.0 logistro-2.0.1 ml_dtypes-0.5.4 mthree-3.0.0 multitasking-0.0.12 narwhals-2.13.0 netCDF4-1.7.3 networkx-2.8.5 nvidia-nccl-cu12-2.27.5 nvidia-nvshmem-cu12-3.3.20 opencensus-0.11.4 opencensus-context-0.1.3 openqasm3-1.0.1 opentelemetry-api-1.33.0 opentelemetry-exporter-otlp-proto-common-1.33.0 opentelemetry-exporter-otlp-proto-grpc-1.33.0 opentelemetry-exporter-prometheus-0.54b0 opentelemetry-instrumentation-0.54b0 opentelemetry-instrumentation-requests-0.54b0 opentelemetry-proto-1.33.0 opentelemetry-sdk-1.33.0 opentelemetry-semantic-conventions-0.54b0 opentelemetry-util-http-0.54b0 opt_einsum-3.4.0 osqp-1.0.5 partd-1.4.2 pauli-prop-0.1.0 peewee-3.18.3 pip-25.3 plotly-6.5.0 pluggy-1.6.0 plum-dispatch-2.6.0 portalocker-3.2.0 proto-plus-1.26.1 protobuf-5.29.5 py-spy-0.4.1 pyarrow-18.1.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.3 pymatching-2.3.1 pymupdf-1.26.6 pysat-3.2.2 pyscf-2.11.0 pyspnego-0.12.0 pytest-9.0.2 pytest-timeout-2.4.0 python-dotenv-1.2.1 python-sat-1.8.dev24 qiskit-2.2.3 qiskit-addon-aqc-tensor-0.2.0 qiskit-addon-mpf-0.3.0 qiskit-addon-obp-0.3.0 qiskit-addon-pna-0.2.0 qiskit-addon-slc-0.1.0 qiskit-addon-sqd-0.12.0 qiskit-addon-utils-0.3.0 qiskit-aer-0.17.2 qiskit-experiments-0.13.0 qiskit-ibm-experiment-0.4.8 qiskit-ibm-runtime-0.43.1 qiskit-ibm-transpiler-0.15.0 qiskit-machine-learning-0.8.2 qiskit-qasm3-import-0.6.0 qiskit-quimb-0.0.9 qiskit-serverless-0.27.1 qiskit_ibm_ai_local_transpiler-0.5.5 quimb-1.11.2 ray-2.52.1 requests-ntlm-1.3.0 rsa-4.9.1 runningman-2.3.0 rustworkx-0.17.1 samplomatic-0.13.0 scs-3.2.9 smart_open-7.5.0 stevedore-5.6.0 symengine-0.13.0 synthetic-data-0.1.0 toolz-1.1.0 torch-2.9.1 triton-3.5.1 uncertainties-3.2.3 wand-0.6.13 websockets-15.0.1 wrapt-1.17.3 xarray-2025.12.0 yfinance-0.2.66 zipp-3.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mPnvpgCWFcsK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPnvpgCWFcsK",
        "outputId": "47ddeedb-4e7b-48f0-a936-f57cbe59a905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected OS: Linux\n",
            "Detected Architecture: x86_64\n",
            "Downloading from: https://github.com/huggingface/xet-core/releases/download/git-xet-v0.2.0/git-xet-linux-x86_64.zip...\n",
            "Unzipping...\n",
            "Setting executable permissions...\n",
            "Installing to /usr/local/bin...\n",
            "git-xet installed to global config!\n",
            "git-lfs is not installed. Please install it for git-xet to work. Install it from https://git-lfs.com/\n",
            "Installation complete!\n",
            "Cleaning up...\n",
            "git-xet installed to global config!\n"
          ]
        }
      ],
      "source": [
        "!curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/huggingface/xet-core/refs/heads/main/git_xet/install.sh | sh\n",
        "!git xet install"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7koV-BTuHbbR",
      "metadata": {
        "id": "7koV-BTuHbbR"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7be2632a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting hf_transfer\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf_transfer\n",
            "Successfully installed hf_transfer-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install hf_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2s9U_AtcHgOL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s9U_AtcHgOL",
        "outputId": "42eb34fc-3a8c-437e-e02a-872e988fe21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m╭──────────────────────────────╮\u001b[0m\n",
            "\u001b[36m│\u001b[0m \u001b[1;36mms-swift Dataset Preparation\u001b[0m \u001b[36m│\u001b[0m\n",
            "\u001b[36m╰──────────────────────────────╯\u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mDataset (Hub)   \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32msamuellimabraz/quantum-assistant\u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mOutput directory\u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32m/outputs/swift_data             \u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mImage max size  \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32m640                             \u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mImage format    \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32mJPEG                            \u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mSystem prompt   \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32mYes                             \u001b[0m\u001b[32m \u001b[0m\n",
            "\n",
            "Loading dataset from HuggingFace Hub: samuellimabraz/quantum-assistant\n",
            "README.md: 100%|███████████████████████████████| 767/767 [00:00<00:00, 4.51MB/s]\n",
            "data/train-00000-of-00001.parquet: 100%|█████| 222M/222M [00:03<00:00, 58.0MB/s]\n",
            "data/validation-00000-of-00001.parquet: 100%|█| 45.9M/45.9M [00:02<00:00, 20.3MB\n",
            "data/test-00000-of-00001.parquet: 100%|████| 50.9M/50.9M [00:01<00:00, 25.7MB/s]\n",
            "Generating train split: 100%|█████| 5837/5837 [00:00<00:00, 18471.02 examples/s]\n",
            "Generating validation split: 100%|█| 1239/1239 [00:00<00:00, 20746.89 examples/s\n",
            "Generating test split: 100%|██████| 1290/1290 [00:00<00:00, 44851.43 examples/s]\n",
            "\n",
            "Processing train split (5837 samples)\n",
            "  train: 100%|█████████████████████████████| 5837/5837 [00:30<00:00, 194.01it/s]\n",
            "\n",
            "Processing validation split (1239 samples)\n",
            "  validation: 100%|████████████████████████| 1239/1239 [00:06<00:00, 193.33it/s]\n",
            "\n",
            "Processing test split (1290 samples)\n",
            "  test: 100%|██████████████████████████████| 1290/1290 [00:06<00:00, 188.60it/s]\n",
            "\n",
            "Summary saved to /outputs/swift_data/summary.json\n",
            "Total images processed: 2932\n",
            "\u001b[32m╭──────────────────────╮\u001b[0m\n",
            "\u001b[32m│\u001b[0m \u001b[1;32mPreparation Complete\u001b[0m \u001b[32m│\u001b[0m\n",
            "\u001b[32m╰──────────────────────╯\u001b[0m\n",
            "\u001b[3m                         Results by Split                         \u001b[0m\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mSplit     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTotal\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMultimodal\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mText-only\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36mtrain     \u001b[0m\u001b[36m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mtrain.jsonl     \u001b[0m\u001b[2m \u001b[0m│  5837 │\u001b[33m \u001b[0m\u001b[33m      2633\u001b[0m\u001b[33m \u001b[0m│      3204 │\n",
            "│\u001b[36m \u001b[0m\u001b[36mvalidation\u001b[0m\u001b[36m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mvalidation.jsonl\u001b[0m\u001b[2m \u001b[0m│  1239 │\u001b[33m \u001b[0m\u001b[33m       560\u001b[0m\u001b[33m \u001b[0m│       679 │\n",
            "│\u001b[36m \u001b[0m\u001b[36mtest      \u001b[0m\u001b[36m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mtest.jsonl      \u001b[0m\u001b[2m \u001b[0m│  1290 │\u001b[33m \u001b[0m\u001b[33m       581\u001b[0m\u001b[33m \u001b[0m│       709 │\n",
            "└────────────┴──────────────────┴───────┴────────────┴───────────┘\n"
          ]
        }
      ],
      "source": [
        "!finetune prepare --hub-id samuellimabraz/quantum-assistant --output-dir /outputs/swift_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ba8d08",
      "metadata": {
        "id": "99ba8d08"
      },
      "source": [
        "## SwiftSft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3U3Nt-CWMF_u",
      "metadata": {
        "id": "3U3Nt-CWMF_u"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "iFWaW9XAHBox",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFWaW9XAHBox",
        "outputId": "5bfe1ab2-fcc3-4e7f-dda1-779a8a6b802e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] Successfully registered `/usr/local/lib/python3.12/dist-packages/swift/llm/dataset/data/dataset_info.json`.\n",
            "[INFO:swift] Global seed set to 42\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['USE_HF'] = '1'\n",
        "os.environ['MAX_PIXELS'] = str(1280 * 28 * 28)\n",
        "\n",
        "\n",
        "from swift.utils import get_logger, get_model_parameter_info, plot_images, seed_everything\n",
        "from swift.llm.train.sft import SwiftSft\n",
        "from swift.llm import TrainArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "logger = get_logger()\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "OwEsA3lqVH2S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwEsA3lqVH2S",
        "outputId": "e923876e-8381-4fe7-c82b-124bc63ab523"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3679aa47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4c4a33470a224792b51a86540e6eceff",
            "b6f2ffe8a04f484ca3a01b00b69a483a",
            "1a218d84ac074be3aa418fd358447edc",
            "44cf7f7db20e48febf521c6f7abebe5d",
            "284853260a2148bcbfbaba138abf995c",
            "3cd9cf3ea2924602b12fbee631eb5d44",
            "080edebc63e145d1baac0b0af8d71689",
            "438453698b5a4e71b6d36cd462153448",
            "101f50ee24c549e59573aa5bac1d46c0",
            "386d0945f93e46be90788aa0f90420ab",
            "0deb37ab07b4470d86834e7f0e14f3e9",
            "aa80589f298e431eac10d7edba0c174b",
            "7aa28ae5670240ba9e24baade5daf6fe",
            "b8dc57580fa24f138f112e71130821ca",
            "78824336e49c44129a3d806cd5f05d62",
            "afae93401e354aaab13ffc5dff0d0487",
            "860190e272954723bc22afe0d438fc10",
            "f78ddb9354e0482ab922c873983f5c0f",
            "546cfd35dcbe4c6494cf0d87dd362c71",
            "5244ef41bc1947f8b2e09269dc464f58",
            "6004f096640a4e41a005c5ef5bffa7e7",
            "ef00afa81c3e455a87518000206d2fba"
          ]
        },
        "id": "3679aa47",
        "outputId": "b2ed83a8-acb4-4c97-c93d-5cb9504a46ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] output_dir: /content/quantum-assistant/train/Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned\n",
            "[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: Qwen/Qwen3-VL-2B-Instruct\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c4a33470a224792b51a86540e6eceff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203\n",
            "[INFO:swift] Because len(args.val_dataset) > 0, setting split_dataset_ratio: 0.0\n",
            "[INFO:swift] output_dir: /content/quantum-assistant/train/Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned/v1-20251207-214742\n",
            "[INFO:swift] Global seed set to 42\n",
            "[INFO:swift] args: TrainArguments(\n",
            "_n_gpu=-1,\n",
            "acc_strategy=token,\n",
            "accelerator_config={'dispatch_batches': False},\n",
            "adafactor=False,\n",
            "adalora_beta1=0.85,\n",
            "adalora_beta2=0.85,\n",
            "adalora_deltaT=1,\n",
            "adalora_init_r=12,\n",
            "adalora_orth_reg_weight=0.5,\n",
            "adalora_target_r=8,\n",
            "adalora_tfinal=0,\n",
            "adalora_tinit=0,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.95,\n",
            "adam_epsilon=1e-08,\n",
            "adapter_act=gelu,\n",
            "adapter_length=128,\n",
            "adapters=[],\n",
            "add_version=True,\n",
            "agent_template=None,\n",
            "aligner_lr=None,\n",
            "attn_impl=flash_attn,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "bnb_4bit_compute_dtype=torch.bfloat16,\n",
            "bnb_4bit_quant_storage=None,\n",
            "bnb_4bit_quant_type=nf4,\n",
            "bnb_4bit_use_double_quant=True,\n",
            "boft_block_num=0,\n",
            "boft_block_size=4,\n",
            "boft_dropout=0.0,\n",
            "boft_n_butterfly_factor=1,\n",
            "cached_dataset=[],\n",
            "check_model=True,\n",
            "ckpt_dir=None,\n",
            "columns={},\n",
            "create_checkpoint_symlink=False,\n",
            "custom_dataset_info=[],\n",
            "custom_register_path=[],\n",
            "data_seed=42,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset=['/content/swift_data/train.jsonl'],\n",
            "dataset_num_proc=1,\n",
            "dataset_shuffle=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=18000000,\n",
            "debug=,\n",
            "deepspeed=None,\n",
            "deepspeed_autotp_size=None,\n",
            "device_groups=None,\n",
            "device_map=None,\n",
            "disable_tqdm=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "download_mode=reuse_dataset_if_exists,\n",
            "ds3_gather_for_generation=True,\n",
            "early_stop_interval=None,\n",
            "enable_channel_loss=False,\n",
            "enable_dft_loss=False,\n",
            "eval_accumulation_steps=4,\n",
            "eval_dataset=[],\n",
            "eval_dataset_args=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_generation_config=None,\n",
            "eval_limit=None,\n",
            "eval_on_start=False,\n",
            "eval_steps=20,\n",
            "eval_strategy=steps,\n",
            "eval_use_evalscope=False,\n",
            "eval_use_gather_object=False,\n",
            "external_plugins=[],\n",
            "extra_eval_args=None,\n",
            "fourier_n_frequency=2000,\n",
            "fourier_scaling=300.0,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=True,\n",
            "fp16_opt_level=O1,\n",
            "freeze_aligner=True,\n",
            "freeze_llm=False,\n",
            "freeze_parameters=[],\n",
            "freeze_parameters_ratio=0.0,\n",
            "freeze_parameters_regex=None,\n",
            "freeze_vit=True,\n",
            "fsdp=[],\n",
            "fsdp_config=None,\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "galore_cos_threshold=0.4,\n",
            "galore_gamma_proj=2,\n",
            "galore_optim_per_parameter=False,\n",
            "galore_proj_bits=4,\n",
            "galore_proj_group_size=256,\n",
            "galore_proj_quant=False,\n",
            "galore_proj_type=std,\n",
            "galore_quantization=False,\n",
            "galore_queue_size=5,\n",
            "galore_rank=128,\n",
            "galore_scale=1.0,\n",
            "galore_target_modules=None,\n",
            "galore_update_proj_gap=50,\n",
            "galore_with_embedding=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hqq_axis=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=samuellimabraz/Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned,\n",
            "hub_private_repo=True,\n",
            "hub_revision=None,\n",
            "hub_strategy=end,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_args_error=False,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "init_strategy=None,\n",
            "init_weights=True,\n",
            "interleave_prob=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "lazy_tokenize=False,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "lisa_activated_layers=0,\n",
            "lisa_step_interval=20,\n",
            "llamapro_num_groups=None,\n",
            "llamapro_num_new_blocks=4,\n",
            "load_args=False,\n",
            "load_best_model_at_end=True,\n",
            "load_data_args=False,\n",
            "load_from_cache_file=True,\n",
            "local_rank=-1,\n",
            "local_repo_path=None,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/quantum-assistant/train/Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned/v1-20251207-214742/runs,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5,\n",
            "logging_strategy=steps,\n",
            "logprobs=False,\n",
            "lora_alpha=16,\n",
            "lora_bias=none,\n",
            "lora_dropout=0.05,\n",
            "lora_dtype=None,\n",
            "lora_ga_batch_size=2,\n",
            "lora_ga_direction=ArB2r,\n",
            "lora_ga_iters=2,\n",
            "lora_ga_max_length=1024,\n",
            "lora_ga_scale=stable,\n",
            "lora_ga_stable_gamma=16,\n",
            "lora_modules=[],\n",
            "lora_rank=8,\n",
            "lorap_lr_ratio=None,\n",
            "loss_scale=default,\n",
            "loss_type=None,\n",
            "lr_scheduler_kwargs=None,\n",
            "lr_scheduler_type=cosine,\n",
            "max_epochs=None,\n",
            "max_grad_norm=1.0,\n",
            "max_length=262144,\n",
            "max_memory={},\n",
            "max_model_len=None,\n",
            "max_new_tokens=4096,\n",
            "max_pixels=1003520,\n",
            "max_steps=-1,\n",
            "metric=None,\n",
            "metric_for_best_model=eval_loss,\n",
            "model=Qwen/Qwen3-VL-2B-Instruct,\n",
            "model_author=samuellimabraz,\n",
            "model_kwargs={},\n",
            "model_name=Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned,\n",
            "model_revision=None,\n",
            "model_type=qwen3_vl,\n",
            "modules_to_save=[],\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "new_special_tokens=[],\n",
            "no_cuda=False,\n",
            "norm_bbox=None,\n",
            "num_beams=1,\n",
            "num_labels=None,\n",
            "num_train_epochs=1,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "optimizer=None,\n",
            "output_dir=/content/quantum-assistant/train/Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned/v1-20251207-214742,\n",
            "overwrite_output_dir=False,\n",
            "packing=False,\n",
            "packing_length=None,\n",
            "padding_free=True,\n",
            "padding_side=left,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "problem_type=None,\n",
            "project=quantum-assistant,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "quant_bits=None,\n",
            "quant_method=None,\n",
            "ray_exp_name=None,\n",
            "ray_scope=last,\n",
            "reft_args=None,\n",
            "reft_intervention_type=LoreftIntervention,\n",
            "reft_layer_key=None,\n",
            "reft_layers=None,\n",
            "reft_rank=4,\n",
            "remove_unused_columns=False,\n",
            "repetition_penalty=None,\n",
            "report_to=['wandb', 'tensorboard'],\n",
            "response_prefix=None,\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "resume_only_model=False,\n",
            "rope_scaling=None,\n",
            "router_aux_loss_coef=0.0,\n",
            "run_name=Qwen3-VL-2B-Instruct-r8-rslora-bf16-tuned,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=best,\n",
            "save_total_limit=5,\n",
            "seed=42,\n",
            "sequence_parallel_size=1,\n",
            "shuffle_buffer_size=1000,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_dataset_ratio=0.0,\n",
            "stop_words=[],\n",
            "stopping_strategy=first_exhausted,\n",
            "stream=False,\n",
            "streaming=False,\n",
            "strict=False,\n",
            "swanlab_exp_name=None,\n",
            "swanlab_lark_secret=None,\n",
            "swanlab_lark_webhook_url=None,\n",
            "swanlab_mode=cloud,\n",
            "swanlab_project=None,\n",
            "swanlab_token=<SWANLAB_TOKEN>,\n",
            "swanlab_workspace=None,\n",
            "system=None,\n",
            "target_modules=all-linear,\n",
            "target_parameters=None,\n",
            "target_regex=None,\n",
            "task_type=causal_lm,\n",
            "temperature=0.0,\n",
            "template=qwen3_vl,\n",
            "template_backend=swift,\n",
            "tf32=None,\n",
            "top_k=None,\n",
            "top_logprobs=None,\n",
            "top_p=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_dtype=torch.bfloat16,\n",
            "torch_empty_cache_steps=50,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "train_dataloader_shuffle=True,\n",
            "train_type=lora,\n",
            "trainable_parameters=[],\n",
            "trainable_parameters_regex=None,\n",
            "truncation_strategy=delete,\n",
            "tuner_backend=peft,\n",
            "use_chat_template=True,\n",
            "use_cpu=False,\n",
            "use_dora=False,\n",
            "use_flash_ckpt=False,\n",
            "use_galore=False,\n",
            "use_hf=True,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_logits_to_keep=None,\n",
            "use_mps_device=False,\n",
            "use_ray=False,\n",
            "use_rslora=True,\n",
            "use_swift_lora=False,\n",
            "val_dataset=['/content/swift_data/validation.jsonl'],\n",
            "val_dataset_shuffle=False,\n",
            "vera_d_initial=0.1,\n",
            "vera_dropout=0.0,\n",
            "vera_projection_prng_key=0,\n",
            "vera_rank=256,\n",
            "vit_gradient_checkpointing=None,\n",
            "vit_lr=None,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=10,\n",
            "weight_decay=0.01,\n",
            "zero_hpz_partition_size=None,\n",
            ")\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: Qwen/Qwen3-VL-2B-Instruct\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa80589f298e431eac10d7edba0c174b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203\n",
            "[INFO:swift] attn_impl: flash_attn\n",
            "[INFO:swift] model_kwargs: {'device_map': 'cuda:0', 'dtype': torch.bfloat16}\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3489147039.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0msft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwiftSft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m sft.callbacks.append(\n\u001b[1;32m     84\u001b[0m     EarlyStoppingCallback(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/train/sft.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_model_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/ray/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mRayHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mray_inited\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mRayHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/train/sft.py\u001b[0m in \u001b[0;36m_prepare_model_tokenizer\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_model_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_parallel_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mswift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/argument/base_args/base_args.py\u001b[0m in \u001b[0;36mget_model_processor\u001b[0;34m(self, model, model_type, model_revision, task_type, num_labels, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_model_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/register.py\u001b[0m in \u001b[0;36mget_model_tokenizer\u001b[0;34m(model_id_or_path, torch_dtype, device_map, load_model, use_hf, hub_token, revision, download_model, model_type, quantization_config, max_memory, attn_impl, new_special_tokens, rope_scaling, max_model_len, automodel_class, task_type, num_labels, return_dummy_model, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mpatch_offload_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_attach_align_device_hook_on_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpatch_offload\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpatch_get_dynamic_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_tp_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_offload_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedTokenizerBase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/model/qwen.py\u001b[0m in \u001b[0;36mget_model_tokenizer_qwen3_vl\u001b[0;34m(model_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'automodel_class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'automodel_class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mQwen3VLForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_check_qwen_vl_utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_tokenizer_qwen2_vl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0m_compat_qwen3_vl_mixed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/model/qwen.py\u001b[0m in \u001b[0;36mget_model_tokenizer_qwen2_vl\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQwen2VLForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'automodel_class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'automodel_class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mQwen2VLForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_tokenizer_multimodal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'AWQ'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/register.py\u001b[0m in \u001b[0;36mget_model_tokenizer_multimodal\u001b[0;34m(model_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_tokenizer_with_flash_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/register.py\u001b[0m in \u001b[0;36mget_model_tokenizer_with_flash_attn\u001b[0;34m(model_dir, model_info, model_kwargs, load_model, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mAttnImpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_attn_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_impl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_impl_keys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_model_tokenizer_from_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/register.py\u001b[0m in \u001b[0;36mget_model_tokenizer_from_local\u001b[0;34m(model_dir, model_info, model_kwargs, load_model, tokenizer, model_config, automodel_class, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_automodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcontext_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 model = automodel_class.from_pretrained(\n\u001b[0m\u001b[1;32m    349\u001b[0m                     model_dir, config=model_config, trust_remote_code=True, **model_kwargs)\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/swift/llm/model/patcher.py\u001b[0m in \u001b[0;36m_new_from_pretrained\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_torch_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4972\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_init_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4973\u001b[0m             \u001b[0;31m# Let's make sure we don't run the init function of buffer modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4974\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4976\u001b[0m         \u001b[0;31m# Make sure to tie the weights correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQwen3VLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2078\u001b[0m         \u001b[0;31m# Check the attention implementation is supported, or set it if not yet set (on the internal attr, to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# setting it recursively)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m         self.config._attn_implementation_internal = self._check_and_adjust_attn_implementation(\n\u001b[0m\u001b[1;32m   2081\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn_implementation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_init_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_check_and_adjust_attn_implementation\u001b[0;34m(self, attn_implementation, is_init_check)\u001b[0m\n\u001b[1;32m   2688\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m             applicable_attn_implementation = self.get_correct_attn_implementation(\n\u001b[0m\u001b[1;32m   2691\u001b[0m                 \u001b[0mapplicable_attn_implementation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_init_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mget_correct_attn_implementation\u001b[0;34m(self, requested_attention, is_init_check)\u001b[0m\n\u001b[1;32m   2716\u001b[0m         \u001b[0;31m# Perform relevant checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapplicable_attention\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"flash_attention_2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2718\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flash_attn_2_can_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_init_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2719\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mapplicable_attention\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"flash_attention_3\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flash_attn_3_can_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_init_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_flash_attn_2_can_dispatch\u001b[0;34m(self, is_init_check)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flash_attn\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{preface} the package flash_attn seems to be not installed. {install_message}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m                 \u001b[0;31m# Check FA2 installed version compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model_id_or_path = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
        "model_name = model_id_or_path.split('/')[-1] + '-r8-rslora-bf16-tuned'\n",
        "output_dir = os.path.join(os.getcwd(), \"train\", model_name)\n",
        "\n",
        "logger.info(f'output_dir: {output_dir}')\n",
        "\n",
        "args = TrainArguments(\n",
        "    model=model_id_or_path,\n",
        "    model_name = model_name,\n",
        "    model_author=\"samuellimabraz\",\n",
        "    dataset=['/content/swift_data/train.jsonl'],\n",
        "    val_dataset=['/content/swift_data/validation.jsonl'],\n",
        "    load_from_cache_file=True,\n",
        "    torch_dtype='bfloat16',\n",
        "    max_pixels=1280 * 28 * 28,\n",
        "    attn_impl='flash_attn', #'sdpa'\n",
        "    padding_side='left',\n",
        "    padding_free=True,\n",
        "    # packing=True,\n",
        "    lazy_tokenize=False,\n",
        "    #max_length=8192,\n",
        "    max_new_tokens=4096,\n",
        "    temperature=0.,\n",
        "\n",
        "    # LoRA\n",
        "    train_type='lora',\n",
        "    lora_rank=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules='all-linear',\n",
        "    init_weights='true',\n",
        "    use_rslora=True,\n",
        "    freeze_llm=False,\n",
        "    freeze_vit=True,\n",
        "    freeze_aligner=True,\n",
        "\n",
        "    # Train\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=2e-4,\n",
        "    #auto_find_batch_size=True,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        "    torch_empty_cache_steps = 50,\n",
        "    gradient_checkpointing=True,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps = 10,\n",
        "    warmup_ratio=0.05,\n",
        "    num_train_epochs=1,\n",
        "    lr_scheduler_type='cosine',\n",
        "    optim = \"adamw_torch\",\n",
        "    # neftune_noise_alpha=10,\n",
        "    logging_first_step=True,\n",
        "    logging_steps=5,\n",
        "    logging_strategy=\"steps\",\n",
        "    fp16 = not torch.cuda.is_bf16_supported(),\n",
        "    bf16 = torch.cuda.is_bf16_supported(),\n",
        "\n",
        "    # Eval\n",
        "    fp16_full_eval = True,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    eval_accumulation_steps = 4,\n",
        "    eval_strategy = \"steps\",\n",
        "    eval_steps = 20,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    save_strategy='best',\n",
        "    save_total_limit=5,\n",
        "    dataloader_num_workers=4,\n",
        "    remove_unused_columns=False,\n",
        "    data_seed=42,\n",
        "    report_to=[\"wandb\", \"tensorboard\"],\n",
        "\n",
        "    use_hf=True,\n",
        "    push_to_hub=True,\n",
        "    hub_private_repo=True,\n",
        "    hub_strategy=\"end\",\n",
        "    hub_model_id=f\"samuellimabraz/{model_name}\",\n",
        "    project=\"quantum-assistant\",\n",
        "    run_name=model_name\n",
        ")\n",
        "sft = SwiftSft(args)\n",
        "sft.callbacks.append(\n",
        "    EarlyStoppingCallback(\n",
        "        early_stopping_patience=5,\n",
        "        early_stopping_threshold=0.001\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "M5gaqSTCJ2MZ",
      "metadata": {
        "id": "M5gaqSTCJ2MZ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"quantum-assistant\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xBwf_r49M7PD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b0e4110ea0b84bca9434fe2c72f90543",
            "6eed405af8934dc39eab95854354281e",
            "8624942a65ec413e8246d7e2f813e3d2",
            "ae4775a13ca446da9c99d102038fbac5",
            "9f34af8aed1c407ba1805f337c5d9228",
            "9f47deb2f2e6474ea8b77e728ffbbf77",
            "b3e7e510b4234d2a907d54336aa2f29f",
            "2ac3d00f60f542e99c0903fcd7e5b896",
            "7a82a2cbdf30473c95e1fb762fdfaa23",
            "1bba9d5e6fcf4328be37e2ef5c9370fe",
            "5b14724e198040399f603fb07b6c6d69",
            "f0f6551654ef44aabdc8f7b11243095d",
            "33dfda509e0d4893a1eb212f3fda1a69",
            "0567107daa1a4e88984b9ba55458131e",
            "08cda4f5a3dd4b3db9b624cb2e7e1103",
            "bc6f34e10ed6465587cc16ab9309b523",
            "4e2626615b6844498abec6f75822bfd2",
            "7355317cd4ec4ad3854257d6d73391a5",
            "a81e997ab37e4bb18e70d243079a0fbd",
            "07d8ada74dab4b8695670d46c3ac72df",
            "8b806f79844a4d01bacf3d448b0b158b",
            "388ac21acdd045fea5a62df55d73ec5e"
          ]
        },
        "id": "xBwf_r49M7PD",
        "outputId": "648c4cdd-f591-4e27-d1e3-1391696d0712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] Start time of running main: 2025-12-07 18:57:35.248979\n",
            "[INFO:swift] swift.__version__: 3.10.3\n",
            "[INFO:swift] SelfCognitionPreprocessor has been successfully configured with name: ('Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned', 'Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned'), author: ('samuellimabraz', 'samuellimabraz').\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0e4110ea0b84bca9434fe2c72f90543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5837 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0f6551654ef44aabdc8f7b11243095d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1239 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO:swift] train_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 5837\n",
            "})\n",
            "[INFO:swift] val_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 1239\n",
            "})\n",
            "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 30128, 24231, 6203, 17847, 57294, 304, 1207, 3187, 275, 13, 39565, 13382, 11, 2797, 11, 323, 1632, 12, 51143, 14507, 911, 30128, 24231, 18940, 11, 25185, 11, 323, 2038, 8129, 13, 5443, 1207, 3187, 275, 220, 17, 13, 15, 1850, 12378, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 198, 4021, 279, 30128, 16224, 43794, 304, 279, 2168, 25, 264, 220, 18, 55964, 80, 59220, 16224, 1380, 264, 23864, 309, 567, 18126, 374, 9251, 311, 2804, 59220, 378, 107, 17, 11, 8110, 553, 264, 356, 14065, 448, 2524, 378, 107, 17, 323, 2169, 378, 107, 16, 11, 264, 13387, 2537, 1948, 2804, 81402, 378, 107, 15, 323, 378, 107, 16, 11, 323, 2441, 356, 14065, 448, 2524, 378, 107, 17, 323, 2169, 378, 107, 16, 13, 1446, 1969, 4211, 419, 1667, 264, 729, 6941, 1565, 5834, 1523, 40991, 666, 87, 666, 37268, 63, 448, 902, 5977, 13, 151645, 198, 151644, 77091, 198, 1499, 2804, 3187, 275, 1159, 55313, 34, 37268, 271, 750, 1936, 1523, 40991, 666, 87, 666, 37268, 3932, 262, 77066, 284, 55313, 34, 37268, 7, 18, 340, 262, 77066, 860, 7, 17, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 77066, 54537, 7, 15, 11, 220, 16, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [INPUT] <|im_start|>system\n",
            "You are a quantum computing expert assistant specializing in Qiskit. Provide accurate, clear, and well-structured responses about quantum computing concepts, algorithms, and code implementation. Use Qiskit 2.0 best practices.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|vision_start|>[151655 * 77]<|vision_end|>\n",
            "Create the quantum circuit depicted in the image: a 3‑qubit circuit where a Hadamard gate is applied to qubit 2, followed by a CNOT with control 2 and target 1, a SWAP between qubits 0 and 1, and another CNOT with control 2 and target 1. You must implement this using a function named `build_h_swap_cx_circuit` with no arguments.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "from qiskit import QuantumCircuit\n",
            "\n",
            "def build_h_swap_cx_circuit():\n",
            "    qc = QuantumCircuit(3)\n",
            "    qc.h(2)\n",
            "    qc.cx(2, 1)\n",
            "    qc.swap(0, 1)\n",
            "    qc.cx(2, 1)\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1499, 2804, 3187, 275, 1159, 55313, 34, 37268, 271, 750, 1936, 1523, 40991, 666, 87, 666, 37268, 3932, 262, 77066, 284, 55313, 34, 37268, 7, 18, 340, 262, 77066, 860, 7, 17, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 77066, 54537, 7, 15, 11, 220, 16, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [LABELS] [-100 * 235]from qiskit import QuantumCircuit\n",
            "\n",
            "def build_h_swap_cx_circuit():\n",
            "    qc = QuantumCircuit(3)\n",
            "    qc.h(2)\n",
            "    qc.cx(2, 1)\n",
            "    qc.swap(0, 1)\n",
            "    qc.cx(2, 1)\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] The TrainArguments will be saved in: /content/train/Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned/v0-20251207-185719/args.json\n",
            "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17', revision=None, inference_mode=False, r=8, target_modules='^(model.language_model.*\\\\.(gate_proj|up_proj|k_proj|v_proj|down_proj|q_proj|o_proj))$', exclude_modules=None, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
            "[INFO:swift] model: PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): Qwen3VLForConditionalGeneration(\n",
            "      (model): Qwen3VLModel(\n",
            "        (visual): Qwen3VLVisionModel(\n",
            "          (patch_embed): Qwen3VLVisionPatchEmbed(\n",
            "            (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
            "          )\n",
            "          (pos_embed): Embedding(2304, 1024)\n",
            "          (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
            "          (blocks): ModuleList(\n",
            "            (0-23): 24 x Qwen3VLVisionBlock(\n",
            "              (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (attn): Qwen3VLVisionAttention(\n",
            "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              )\n",
            "              (mlp): Qwen3VLVisionMLP(\n",
            "                (linear_fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (linear_fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (act_fn): GELUTanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (merger): Qwen3VLVisionPatchMerger(\n",
            "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "            (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "            (act_fn): GELU(approximate='none')\n",
            "            (linear_fc2): Linear(in_features=4096, out_features=2560, bias=True)\n",
            "          )\n",
            "          (deepstack_merger_list): ModuleList(\n",
            "            (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
            "              (norm): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
            "              (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "              (act_fn): GELU(approximate='none')\n",
            "              (linear_fc2): Linear(in_features=4096, out_features=2560, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (language_model): Qwen3VLTextModel(\n",
            "          (embed_tokens): Embedding(151936, 2560)\n",
            "          (layers): ModuleList(\n",
            "            (0-35): 36 x Qwen3VLTextDecoderLayer(\n",
            "              (self_attn): Qwen3VLTextAttention(\n",
            "                (q_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "              )\n",
            "              (mlp): Qwen3VLTextMLP(\n",
            "                (gate_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=9728, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (up_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=9728, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (down_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=9728, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (act_fn): SiLUActivation()\n",
            "              )\n",
            "              (input_layernorm): Qwen3VLTextRMSNorm((2560,), eps=1e-06)\n",
            "              (post_attention_layernorm): Qwen3VLTextRMSNorm((2560,), eps=1e-06)\n",
            "            )\n",
            "          )\n",
            "          (norm): Qwen3VLTextRMSNorm((2560,), eps=1e-06)\n",
            "          (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
            "        )\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 4454.3309M Params (16.5151M Trainable [0.3708%]), 0.0001M Buffers.\n",
            "[INFO:swift] use_reentrant: True\n",
            "[INFO:swift] The logging file will be saved in: /content/train/Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned/v0-20251207-185719/logging.jsonl\n",
            "[INFO:swift] Successfully registered post_encode hook: ['PeftModelForCausalLM'].\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None}.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamuellimabraz\u001b[0m (\u001b[33mblackbee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251207_185740-1y5nrdbs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/blackbee/quantum-assistant/runs/1y5nrdbs' target=\"_blank\">Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned</a></strong> to <a href='https://wandb.ai/blackbee/quantum-assistant' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/blackbee/quantum-assistant' target=\"_blank\">https://wandb.ai/blackbee/quantum-assistant</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/blackbee/quantum-assistant/runs/1y5nrdbs' target=\"_blank\">https://wandb.ai/blackbee/quantum-assistant/runs/1y5nrdbs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/366 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: False\n",
            "Train:   0%|          | 1/366 [01:05<6:35:27, 65.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.47564614, 'grad_norm': 3.08612037, 'learning_rate': 2e-05, 'token_acc': 0.75079031, 'epoch': 0.01, 'global_step/max_steps': '1/366', 'percentage': '0.27%', 'elapsed_time': '1m 5s', 'remaining_time': '6h 35m 29s', 'memory(GiB)': 32.71, 'train_speed(iter/s)': 0.015382}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   1%|          | 2/366 [01:52<5:31:39, 54.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.64435577, 'grad_norm': 2.97596097, 'learning_rate': 4e-05, 'token_acc': 0.7217824, 'epoch': 0.01, 'global_step/max_steps': '2/366', 'percentage': '0.55%', 'elapsed_time': '1m 52s', 'remaining_time': '5h 41m 4s', 'memory(GiB)': 36.85, 'train_speed(iter/s)': 0.017787}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   1%|          | 3/366 [03:02<6:14:36, 61.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.37458622, 'grad_norm': 2.69652987, 'learning_rate': 6e-05, 'token_acc': 0.75743661, 'epoch': 0.02, 'global_step/max_steps': '3/366', 'percentage': '0.82%', 'elapsed_time': '3m 2s', 'remaining_time': '6h 9m 1s', 'memory(GiB)': 60.25, 'train_speed(iter/s)': 0.016395}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   1%|          | 4/366 [04:03<6:10:46, 61.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.22692871, 'grad_norm': 2.56138492, 'learning_rate': 8e-05, 'token_acc': 0.77798551, 'epoch': 0.02, 'global_step/max_steps': '4/366', 'percentage': '1.09%', 'elapsed_time': '4m 3s', 'remaining_time': '6h 7m 37s', 'memory(GiB)': 60.25, 'train_speed(iter/s)': 0.016411}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   1%|▏         | 5/366 [05:27<6:57:23, 69.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.22136486, 'grad_norm': 1.9648397, 'learning_rate': 0.0001, 'token_acc': 0.74672152, 'epoch': 0.03, 'global_step/max_steps': '5/366', 'percentage': '1.37%', 'elapsed_time': '5m 27s', 'remaining_time': '6h 33m 39s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.015284}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   2%|▏         | 6/366 [06:45<7:14:56, 72.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.15417612, 'grad_norm': 2.03546643, 'learning_rate': 0.00012, 'token_acc': 0.76683697, 'epoch': 0.03, 'global_step/max_steps': '6/366', 'percentage': '1.64%', 'elapsed_time': '6m 45s', 'remaining_time': '6h 45m 41s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.01479}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   2%|▏         | 7/366 [08:03<7:24:16, 74.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.19977474, 'grad_norm': 1.48850739, 'learning_rate': 0.00014, 'token_acc': 0.73864521, 'epoch': 0.04, 'global_step/max_steps': '7/366', 'percentage': '1.91%', 'elapsed_time': '8m 3s', 'remaining_time': '6h 53m 20s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.014476}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   2%|▏         | 8/366 [09:33<7:53:02, 79.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.14413464, 'grad_norm': 0.84120828, 'learning_rate': 0.00016, 'token_acc': 0.73426408, 'epoch': 0.04, 'global_step/max_steps': '8/366', 'percentage': '2.19%', 'elapsed_time': '9m 33s', 'remaining_time': '7h 7m 49s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.013947}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   2%|▏         | 9/366 [11:46<9:30:51, 95.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.07826519, 'grad_norm': 0.69512147, 'learning_rate': 0.00018, 'token_acc': 0.72084548, 'epoch': 0.05, 'global_step/max_steps': '9/366', 'percentage': '2.46%', 'elapsed_time': '11m 46s', 'remaining_time': '7h 46m 52s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.012744}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   3%|▎         | 10/366 [12:20<7:36:42, 76.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0660578, 'grad_norm': 0.67294222, 'learning_rate': 0.0002, 'token_acc': 0.74028668, 'epoch': 0.05, 'global_step/max_steps': '10/366', 'percentage': '2.73%', 'elapsed_time': '12m 20s', 'remaining_time': '7h 19m 28s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.013501}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   3%|▎         | 11/366 [14:17<8:47:54, 89.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.12724876, 'grad_norm': 0.87927151, 'learning_rate': 0.0002, 'token_acc': 0.71587938, 'epoch': 0.06, 'global_step/max_steps': '11/366', 'percentage': '3.01%', 'elapsed_time': '14m 17s', 'remaining_time': '7h 41m 19s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.012825}\n"
          ]
        }
      ],
      "source": [
        "result = sft.main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vBnzwRegqrAf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBnzwRegqrAf",
        "outputId": "36c388f5-ffab-4e42-d21f-60b2d345d98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "run sh: `/usr/bin/python3 /usr/local/lib/python3.12/dist-packages/swift/cli/sft.py --model Qwen/Qwen3-VL-2B-Instruct --dataset /content/swift_data/train.jsonl --val_dataset /content/swift_data/validation.jsonl --load_from_cache_file true --train_type lora --torch_dtype bfloat16 --num_train_epochs 1 --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --attn_impl sdpa --learning_rate 1e-4 --lora_rank 16 --lora_alpha 32 --target_modules all-linear --freeze_vit true --freeze_aligner true --gradient_checkpointing true --vit_gradient_checkpointing false --gradient_accumulation_steps 2 --eval_steps 100 --save_steps 100 --save_total_limit 2 --logging_steps 5 --max_length 4096 --output_dir output --warmup_ratio 0.05 --dataset_num_proc 4 --dataloader_num_workers 4 --report_to tensorboard wandb --use_hf`\n",
            "2025-12-05 08:47:35.663359: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 08:47:35.682878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764924455.705865   32787 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764924455.713459   32787 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764924455.733106   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764924455.733134   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764924455.733137   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764924455.733140   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 08:47:35.738202: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO:swift] Successfully registered `/usr/local/lib/python3.12/dist-packages/swift/llm/dataset/data/dataset_info.json`.\n",
            "[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: Qwen/Qwen3-VL-2B-Instruct\n",
            "Fetching 11 files: 100% 11/11 [00:00<00:00, 32652.05it/s]\n",
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "[INFO:swift] Because len(args.val_dataset) > 0, setting split_dataset_ratio: 0.0\n",
            "[INFO:swift] Setting args.lazy_tokenize: True\n",
            "[INFO:swift] output_dir: /content/output/v0-20251205-084749\n",
            "[INFO:swift] Global seed set to 42\n",
            "[INFO:swift] args: TrainArguments(\n",
            "_n_gpu=-1,\n",
            "acc_strategy=token,\n",
            "accelerator_config={'dispatch_batches': False},\n",
            "adafactor=False,\n",
            "adalora_beta1=0.85,\n",
            "adalora_beta2=0.85,\n",
            "adalora_deltaT=1,\n",
            "adalora_init_r=12,\n",
            "adalora_orth_reg_weight=0.5,\n",
            "adalora_target_r=8,\n",
            "adalora_tfinal=0,\n",
            "adalora_tinit=0,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.95,\n",
            "adam_epsilon=1e-08,\n",
            "adapter_act=gelu,\n",
            "adapter_length=128,\n",
            "adapters=[],\n",
            "add_version=True,\n",
            "agent_template=None,\n",
            "aligner_lr=None,\n",
            "attn_impl=sdpa,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "bnb_4bit_compute_dtype=torch.bfloat16,\n",
            "bnb_4bit_quant_storage=None,\n",
            "bnb_4bit_quant_type=nf4,\n",
            "bnb_4bit_use_double_quant=True,\n",
            "boft_block_num=0,\n",
            "boft_block_size=4,\n",
            "boft_dropout=0.0,\n",
            "boft_n_butterfly_factor=1,\n",
            "cached_dataset=[],\n",
            "check_model=True,\n",
            "ckpt_dir=None,\n",
            "columns={},\n",
            "create_checkpoint_symlink=False,\n",
            "custom_dataset_info=[],\n",
            "custom_register_path=[],\n",
            "data_seed=42,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset=['/content/swift_data/train.jsonl'],\n",
            "dataset_num_proc=4,\n",
            "dataset_shuffle=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=18000000,\n",
            "debug=None,\n",
            "deepspeed=None,\n",
            "deepspeed_autotp_size=None,\n",
            "device_groups=None,\n",
            "device_map=None,\n",
            "disable_tqdm=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "download_mode=reuse_dataset_if_exists,\n",
            "ds3_gather_for_generation=True,\n",
            "early_stop_interval=None,\n",
            "enable_channel_loss=False,\n",
            "enable_dft_loss=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_dataset=[],\n",
            "eval_dataset_args=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_generation_config=None,\n",
            "eval_limit=None,\n",
            "eval_on_start=False,\n",
            "eval_steps=100.0,\n",
            "eval_strategy=steps,\n",
            "eval_use_evalscope=False,\n",
            "eval_use_gather_object=False,\n",
            "external_plugins=[],\n",
            "extra_eval_args=None,\n",
            "fourier_n_frequency=2000,\n",
            "fourier_scaling=300.0,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "freeze_aligner=True,\n",
            "freeze_llm=False,\n",
            "freeze_parameters=[],\n",
            "freeze_parameters_ratio=0.0,\n",
            "freeze_parameters_regex=None,\n",
            "freeze_vit=True,\n",
            "fsdp=None,\n",
            "fsdp_config=None,\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "galore_cos_threshold=0.4,\n",
            "galore_gamma_proj=2,\n",
            "galore_optim_per_parameter=False,\n",
            "galore_proj_bits=4,\n",
            "galore_proj_group_size=256,\n",
            "galore_proj_quant=False,\n",
            "galore_proj_type=std,\n",
            "galore_quantization=False,\n",
            "galore_queue_size=5,\n",
            "galore_rank=128,\n",
            "galore_scale=1.0,\n",
            "galore_target_modules=None,\n",
            "galore_update_proj_gap=50,\n",
            "galore_with_embedding=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hqq_axis=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_args_error=False,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "init_strategy=None,\n",
            "init_weights=True,\n",
            "interleave_prob=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "lazy_tokenize=True,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "lisa_activated_layers=0,\n",
            "lisa_step_interval=20,\n",
            "llamapro_num_groups=None,\n",
            "llamapro_num_new_blocks=4,\n",
            "load_args=False,\n",
            "load_best_model_at_end=False,\n",
            "load_data_args=False,\n",
            "load_from_cache_file=True,\n",
            "local_rank=-1,\n",
            "local_repo_path=None,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/output/v0-20251205-084749/runs,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5,\n",
            "logging_strategy=steps,\n",
            "logprobs=False,\n",
            "lora_alpha=32,\n",
            "lora_bias=none,\n",
            "lora_dropout=0.05,\n",
            "lora_dtype=None,\n",
            "lora_ga_batch_size=2,\n",
            "lora_ga_direction=ArB2r,\n",
            "lora_ga_iters=2,\n",
            "lora_ga_max_length=1024,\n",
            "lora_ga_scale=stable,\n",
            "lora_ga_stable_gamma=16,\n",
            "lora_modules=[],\n",
            "lora_rank=16,\n",
            "lorap_lr_ratio=None,\n",
            "loss_scale=default,\n",
            "loss_type=None,\n",
            "lr_scheduler_kwargs=None,\n",
            "lr_scheduler_type=cosine,\n",
            "max_epochs=None,\n",
            "max_grad_norm=1.0,\n",
            "max_length=4096,\n",
            "max_memory={},\n",
            "max_model_len=None,\n",
            "max_new_tokens=64,\n",
            "max_pixels=None,\n",
            "max_steps=-1,\n",
            "metric=None,\n",
            "metric_for_best_model=loss,\n",
            "model=Qwen/Qwen3-VL-2B-Instruct,\n",
            "model_author=None,\n",
            "model_kwargs={},\n",
            "model_name=None,\n",
            "model_revision=None,\n",
            "model_type=qwen3_vl,\n",
            "modules_to_save=[],\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "new_special_tokens=[],\n",
            "no_cuda=False,\n",
            "norm_bbox=None,\n",
            "num_beams=1,\n",
            "num_labels=None,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_torch_fused,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "optimizer=None,\n",
            "output_dir=/content/output/v0-20251205-084749,\n",
            "overwrite_output_dir=False,\n",
            "packing=False,\n",
            "packing_length=None,\n",
            "padding_free=False,\n",
            "padding_side=right,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=2,\n",
            "per_device_train_batch_size=2,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "problem_type=None,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "quant_bits=None,\n",
            "quant_method=None,\n",
            "ray_exp_name=None,\n",
            "ray_scope=last,\n",
            "reft_args=None,\n",
            "reft_intervention_type=LoreftIntervention,\n",
            "reft_layer_key=None,\n",
            "reft_layers=None,\n",
            "reft_rank=4,\n",
            "remove_unused_columns=True,\n",
            "repetition_penalty=None,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "response_prefix=None,\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "resume_only_model=False,\n",
            "rope_scaling=None,\n",
            "router_aux_loss_coef=0.0,\n",
            "run_name=/content/output/v0-20251205-084749,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100.0,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "sequence_parallel_size=1,\n",
            "shuffle_buffer_size=1000,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_dataset_ratio=0.0,\n",
            "stop_words=[],\n",
            "stopping_strategy=first_exhausted,\n",
            "stream=False,\n",
            "streaming=False,\n",
            "strict=False,\n",
            "swanlab_exp_name=None,\n",
            "swanlab_lark_secret=None,\n",
            "swanlab_lark_webhook_url=None,\n",
            "swanlab_mode=cloud,\n",
            "swanlab_project=None,\n",
            "swanlab_token=<SWANLAB_TOKEN>,\n",
            "swanlab_workspace=None,\n",
            "system=None,\n",
            "target_modules=['all-linear'],\n",
            "target_parameters=None,\n",
            "target_regex=None,\n",
            "task_type=causal_lm,\n",
            "temperature=0.0,\n",
            "template=qwen3_vl,\n",
            "template_backend=swift,\n",
            "tf32=None,\n",
            "top_k=None,\n",
            "top_logprobs=None,\n",
            "top_p=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_dtype=torch.bfloat16,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "train_dataloader_shuffle=True,\n",
            "train_type=lora,\n",
            "trainable_parameters=[],\n",
            "trainable_parameters_regex=None,\n",
            "truncation_strategy=delete,\n",
            "tuner_backend=peft,\n",
            "use_chat_template=True,\n",
            "use_cpu=False,\n",
            "use_dora=False,\n",
            "use_flash_ckpt=False,\n",
            "use_galore=False,\n",
            "use_hf=True,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_logits_to_keep=None,\n",
            "use_mps_device=False,\n",
            "use_ray=False,\n",
            "use_rslora=False,\n",
            "use_swift_lora=False,\n",
            "val_dataset=['/content/swift_data/validation.jsonl'],\n",
            "val_dataset_shuffle=False,\n",
            "vera_d_initial=0.1,\n",
            "vera_dropout=0.0,\n",
            "vera_projection_prng_key=0,\n",
            "vera_rank=256,\n",
            "vit_gradient_checkpointing=False,\n",
            "vit_lr=None,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.1,\n",
            "zero_hpz_partition_size=None,\n",
            ")\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: Qwen/Qwen3-VL-2B-Instruct\n",
            "Fetching 12 files: 100% 12/12 [00:00<00:00, 19225.23it/s]\n",
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203\n",
            "[INFO:swift] attn_impl: sdpa\n",
            "[INFO:swift] model_kwargs: {'device_map': 'cuda:0', 'dtype': torch.bfloat16}\n",
            "[INFO:swift] Setting max_ratio: 200. You can adjust this hyperparameter through the environment variable: `MAX_RATIO`.\n",
            "[INFO:swift] Setting frame_factor: 2. You can adjust this hyperparameter through the environment variable: `FRAME_FACTOR`.\n",
            "[INFO:swift] Setting fps: 2.0. You can adjust this hyperparameter through the environment variable: `FPS`.\n",
            "[INFO:swift] Setting fps_min_frames: 4. You can adjust this hyperparameter through the environment variable: `FPS_MIN_FRAMES`.\n",
            "[INFO:swift] Setting fps_max_frames: 768. You can adjust this hyperparameter through the environment variable: `FPS_MAX_FRAMES`.\n",
            "[INFO:swift] Using environment variable `IMAGE_MAX_TOKEN_NUM`, Setting image_max_token_num: 1024.\n",
            "[INFO:swift] Setting image_min_token_num: 4. You can adjust this hyperparameter through the environment variable: `IMAGE_MIN_TOKEN_NUM`.\n",
            "[INFO:swift] Setting spatial_merge_size: 2. You can adjust this hyperparameter through the environment variable: `SPATIAL_MERGE_SIZE`.\n",
            "[INFO:swift] Setting video_max_token_num: 768. You can adjust this hyperparameter through the environment variable: `VIDEO_MAX_TOKEN_NUM`.\n",
            "[INFO:swift] Setting video_min_token_num: 128. You can adjust this hyperparameter through the environment variable: `VIDEO_MIN_TOKEN_NUM`.\n",
            "[INFO:swift] model.hf_device_map: {'': device(type='cuda', index=0)}\n",
            "[INFO:swift] model_info: ModelInfo(model_type='qwen3_vl', model_dir='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203', torch_dtype=torch.bfloat16, max_model_len=262144, quant_method=None, quant_bits=None, rope_scaling={'mrope_interleaved': True, 'mrope_section': [24, 20, 20], 'rope_type': 'default'}, is_moe_model=False, config=Qwen3VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"model_type\": \"qwen3_vl\",\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"text_config\": {\n",
            "    \"attention_bias\": false,\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bos_token_id\": 151643,\n",
            "    \"dtype\": \"bfloat16\",\n",
            "    \"eos_token_id\": 151645,\n",
            "    \"head_dim\": 128,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 2048,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 6144,\n",
            "    \"max_position_embeddings\": 262144,\n",
            "    \"model_type\": \"qwen3_vl_text\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_hidden_layers\": 28,\n",
            "    \"num_key_value_heads\": 8,\n",
            "    \"pad_token_id\": 151643,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": {\n",
            "      \"mrope_interleaved\": true,\n",
            "      \"mrope_section\": [\n",
            "        24,\n",
            "        20,\n",
            "        20\n",
            "      ],\n",
            "      \"rope_type\": \"default\"\n",
            "    },\n",
            "    \"rope_theta\": 5000000,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 151936\n",
            "  },\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"deepstack_visual_indexes\": [\n",
            "      5,\n",
            "      11,\n",
            "      17\n",
            "    ],\n",
            "    \"depth\": 24,\n",
            "    \"dtype\": \"bfloat16\",\n",
            "    \"hidden_act\": \"gelu_pytorch_tanh\",\n",
            "    \"hidden_size\": 1024,\n",
            "    \"in_channels\": 3,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 4096,\n",
            "    \"model_type\": \"qwen3_vl\",\n",
            "    \"num_heads\": 16,\n",
            "    \"num_position_embeddings\": 2304,\n",
            "    \"out_hidden_size\": 2048,\n",
            "    \"pad_token_id\": 151643,\n",
            "    \"patch_size\": 16,\n",
            "    \"spatial_merge_size\": 2,\n",
            "    \"temporal_patch_size\": 2\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652\n",
            "}\n",
            ", task_type='causal_lm', num_labels=None)\n",
            "[INFO:swift] model.generation_config: GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"max_new_tokens\": 64,\n",
            "  \"pad_token_id\": 151643\n",
            "}\n",
            "\n",
            "[INFO:swift] default_system: None\n",
            "[INFO:swift] max_length: 4096\n",
            "[INFO:swift] response_prefix: ''\n",
            "[INFO:swift] agent_template: hermes\n",
            "[INFO:swift] norm_bbox: norm1000\n",
            "[INFO:swift] Setting ROOT_IMAGE_DIR: None. You can adjust this hyperparameter through the environment variable: `ROOT_IMAGE_DIR`.\n",
            "[INFO:swift] Setting QWENVL_BBOX_FORMAT: legacy. You can adjust this hyperparameter through the environment variable: `QWENVL_BBOX_FORMAT`.\n",
            "[INFO:swift] Start time of running main: 2025-12-05 08:47:52.414560\n",
            "[INFO:swift] swift.__version__: 3.10.3\n",
            "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 65 examples [00:00, 19908.70 examples/s]\n",
            "Map (num_proc=4): 100% 65/65 [00:00<00:00, 384.81 examples/s]\n",
            "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 22 examples [00:00, 12019.63 examples/s]\n",
            "Map (num_proc=4): 100% 22/22 [00:00<00:00, 145.82 examples/s]\n",
            "[INFO:swift] train_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 65\n",
            "})\n",
            "[INFO:swift] val_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 22\n",
            "})\n",
            "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 30128, 24231, 6203, 17847, 57294, 304, 1207, 3187, 275, 13, 39565, 13382, 11, 2797, 11, 323, 1632, 12, 51143, 14507, 911, 30128, 24231, 18940, 11, 25185, 11, 323, 2038, 8129, 13, 5443, 1207, 3187, 275, 220, 17, 13, 15, 1850, 12378, 13, 151645, 198, 151644, 872, 198, 73594, 12669, 198, 1499, 2804, 3187, 275, 1159, 55313, 34, 37268, 198, 1499, 2804, 3187, 275, 520, 37268, 39285, 1159, 29288, 21807, 10060, 42318, 271, 750, 20908, 28043, 4178, 88, 666, 37268, 27978, 25, 2224, 11, 13440, 25, 2224, 284, 220, 15, 13, 15, 982, 262, 4210, 4021, 264, 220, 17, 55964, 80, 59220, 16224, 429, 16790, 458, 29288, 10, 10060, 16230, 448, 12695, 9210, 1565, 15976, 63, 323, 10262, 1565, 19127, 63, 14442, 262, 1494, 198, 73594, 151645, 198, 151644, 77091, 198, 59833, 284, 55313, 34, 37268, 7, 17, 340, 262, 18126, 284, 29288, 21807, 10060, 42318, 27978, 11, 13440, 340, 262, 77066, 2057, 3268, 349, 11, 508, 15, 11, 220, 16, 2546, 262, 77066, 2196, 58, 15, 936, 9262, 2644, 284, 330, 4146, 10, 4807, 698, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [INPUT] <|im_start|>system\n",
            "You are a quantum computing expert assistant specializing in Qiskit. Provide accurate, clear, and well-structured responses about quantum computing concepts, algorithms, and code implementation. Use Qiskit 2.0 best practices.<|im_end|>\n",
            "<|im_start|>user\n",
            "```python\n",
            "from qiskit import QuantumCircuit\n",
            "from qiskit.circuit.library import XXPlusYYGate\n",
            "\n",
            "def xx_plus_yy_circuit(theta: float, beta: float = 0.0):\n",
            "    \"\"\"Create a 2‑qubit circuit that applies an XX+YY interaction with rotation angle `theta` and phase `beta`.\"\"\"\n",
            "    pass\n",
            "```<|im_end|>\n",
            "<|im_start|>assistant\n",
            "qc = QuantumCircuit(2)\n",
            "    gate = XXPlusYYGate(theta, beta)\n",
            "    qc.append(gate, [0, 1])\n",
            "    qc.data[0].operation.name = \"xx+yy\"\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 59833, 284, 55313, 34, 37268, 7, 17, 340, 262, 18126, 284, 29288, 21807, 10060, 42318, 27978, 11, 13440, 340, 262, 77066, 2057, 3268, 349, 11, 508, 15, 11, 220, 16, 2546, 262, 77066, 2196, 58, 15, 936, 9262, 2644, 284, 330, 4146, 10, 4807, 698, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [LABELS] [-100 * 136]qc = QuantumCircuit(2)\n",
            "    gate = XXPlusYYGate(theta, beta)\n",
            "    qc.append(gate, [0, 1])\n",
            "    qc.data[0].operation.name = \"xx+yy\"\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] The TrainArguments will be saved in: /content/output/v0-20251205-084749/args.json\n",
            "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203', revision=None, inference_mode=False, r=16, target_modules='^(model.language_model.*\\\\.(gate_proj|down_proj|q_proj|o_proj|v_proj|up_proj|k_proj))$', exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
            "[INFO:swift] model: PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): Qwen3VLForConditionalGeneration(\n",
            "      (model): Qwen3VLModel(\n",
            "        (visual): Qwen3VLVisionModel(\n",
            "          (patch_embed): Qwen3VLVisionPatchEmbed(\n",
            "            (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
            "          )\n",
            "          (pos_embed): Embedding(2304, 1024)\n",
            "          (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
            "          (blocks): ModuleList(\n",
            "            (0-23): 24 x Qwen3VLVisionBlock(\n",
            "              (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (attn): Qwen3VLVisionAttention(\n",
            "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              )\n",
            "              (mlp): Qwen3VLVisionMLP(\n",
            "                (linear_fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (linear_fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (act_fn): GELUTanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (merger): Qwen3VLVisionPatchMerger(\n",
            "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "            (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "            (act_fn): GELU(approximate='none')\n",
            "            (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "          )\n",
            "          (deepstack_merger_list): ModuleList(\n",
            "            (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
            "              (norm): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
            "              (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "              (act_fn): GELU(approximate='none')\n",
            "              (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (language_model): Qwen3VLTextModel(\n",
            "          (embed_tokens): Embedding(151936, 2048)\n",
            "          (layers): ModuleList(\n",
            "            (0-27): 28 x Qwen3VLTextDecoderLayer(\n",
            "              (self_attn): Qwen3VLTextAttention(\n",
            "                (q_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "              )\n",
            "              (mlp): Qwen3VLTextMLP(\n",
            "                (gate_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=6144, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=6144, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (up_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=6144, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=6144, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (down_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=6144, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=6144, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (act_fn): SiLUActivation()\n",
            "              )\n",
            "              (input_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
            "              (post_attention_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
            "            )\n",
            "          )\n",
            "          (norm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
            "          (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
            "        )\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 2144.9646M Params (17.4326M Trainable [0.8127%]), 0.0001M Buffers.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "[INFO:swift] use_reentrant: True\n",
            "[INFO:swift] The logging file will be saved in: /content/output/v0-20251205-084749/logging.jsonl\n",
            "[INFO:swift] Successfully registered post_encode hook: ['PeftModelForCausalLM'].\n",
            "[WARNING:swift] prepare gradient_checkpointing failed: 'Qwen3VLVisionModel' object has no attribute '_require_grads_hook'\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamuellimabraz\u001b[0m (\u001b[33mblackbee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251205_084758-ug74pkm5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/content/output/v0-20251205-084749\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/blackbee/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/blackbee/huggingface/runs/ug74pkm5\u001b[0m\n",
            "Train:   0% 0/17 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: False\n",
            "{'loss': 0.85970342, 'grad_norm': 1.90481687, 'learning_rate': 0.0001, 'token_acc': 0.81791908, 'epoch': 0.06, 'global_step/max_steps': '1/17', 'percentage': '5.88%', 'elapsed_time': '6s', 'remaining_time': '1m 44s', 'memory(GiB)': 8.47, 'train_speed(iter/s)': 0.153481}\n",
            "{'loss': 1.01663578, 'grad_norm': 1.80471671, 'learning_rate': 8.536e-05, 'token_acc': 0.77156975, 'epoch': 0.3, 'global_step/max_steps': '5/17', 'percentage': '29.41%', 'elapsed_time': '30s', 'remaining_time': '1m 12s', 'memory(GiB)': 8.5, 'train_speed(iter/s)': 0.165795}\n",
            "{'loss': 1.18291492, 'grad_norm': 1.50467765, 'learning_rate': 4.025e-05, 'token_acc': 0.74276673, 'epoch': 0.61, 'global_step/max_steps': '10/17', 'percentage': '58.82%', 'elapsed_time': '1m 16s', 'remaining_time': '53s', 'memory(GiB)': 8.5, 'train_speed(iter/s)': 0.130746}\n",
            "{'loss': 1.09067736, 'grad_norm': 1.15591311, 'learning_rate': 3.81e-06, 'token_acc': 0.71851852, 'epoch': 0.91, 'global_step/max_steps': '15/17', 'percentage': '88.24%', 'elapsed_time': '2m 12s', 'remaining_time': '17s', 'memory(GiB)': 8.51, 'train_speed(iter/s)': 0.113592}\n",
            "Train: 100% 17/17 [02:44<00:00, 11.77s/it]\n",
            "{'eval_loss': 0.90164608, 'eval_runtime': 53.3679, 'eval_samples_per_second': 0.412, 'eval_steps_per_second': 0.206, 'eval_token_acc': 0.77504052, 'epoch': 1.0, 'global_step/max_steps': '17/17', 'percentage': '100.00%', 'elapsed_time': '3m 38s', 'remaining_time': '0s', 'memory(GiB)': 8.51, 'train_speed(iter/s)': 0.077911}\n",
            "Val: 100% 11/11 [00:46<00:00,  4.20s/it]\n",
            "[INFO:swift] Saving model checkpoint to /content/output/v0-20251205-084749/checkpoint-17\n",
            "{'train_runtime': 221.5605, 'train_samples_per_second': 0.293, 'train_steps_per_second': 0.077, 'train_loss': 1.05035187, 'epoch': 1.0, 'global_step/max_steps': '17/17', 'percentage': '100.00%', 'elapsed_time': '3m 39s', 'remaining_time': '0s', 'memory(GiB)': 8.51, 'train_speed(iter/s)': 0.077502}\n",
            "Train: 100% 17/17 [03:39<00:00, 12.90s/it]\n",
            "[INFO:swift] last_model_checkpoint: /content/output/v0-20251205-084749/checkpoint-17\n",
            "[INFO:swift] best_model_checkpoint: /content/output/v0-20251205-084749/checkpoint-17\n",
            "[INFO:swift] images_dir: /content/output/v0-20251205-084749/images\n",
            "[INFO:swift] End time of running main: 2025-12-05 08:51:41.671839\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m/content/output/v0-20251205-084749\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251205_084758-ug74pkm5/logs\u001b[0m\n",
            "[W1205 08:51:45.502153709 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
            "[W1205 08:51:46.272114041 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
          ]
        }
      ],
      "source": [
        "!PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' \\\n",
        "IMAGE_MAX_TOKEN_NUM=1024 \\\n",
        "CUDA_VISIBLE_DEVICES=0 \\\n",
        "swift sft \\\n",
        "    --model Qwen/Qwen3-VL-4B-Instruct \\\n",
        "    --dataset '/content/swift_data/train.jsonl' \\\n",
        "    --val_dataset '/content/swift_data/validation.jsonl' \\\n",
        "    --load_from_cache_file true \\\n",
        "    --train_type lora \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --attn_impl sdpa \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --lr_scheduler_type cosine \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --target_modules all-linear \\\n",
        "    --freeze_vit true \\\n",
        "    --freeze_aligner false \\\n",
        "    --gradient_checkpointing true \\\n",
        "    --vit_gradient_checkpointing false \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --eval_steps 100 \\\n",
        "    --save_steps 100 \\\n",
        "    --save_total_limit 2 \\\n",
        "    --logging_steps 5 \\\n",
        "    --output_dir output \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --dataset_num_proc 4 \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --report_to tensorboard wandb \\\n",
        "    --use_hf"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uXWvkohn9emo",
        "qjVzSyeT3nmO"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0567107daa1a4e88984b9ba55458131e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a81e997ab37e4bb18e70d243079a0fbd",
            "max": 1239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07d8ada74dab4b8695670d46c3ac72df",
            "tabbable": null,
            "tooltip": null,
            "value": 1239
          }
        },
        "07d8ada74dab4b8695670d46c3ac72df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "080edebc63e145d1baac0b0af8d71689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08cda4f5a3dd4b3db9b624cb2e7e1103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8b806f79844a4d01bacf3d448b0b158b",
            "placeholder": "​",
            "style": "IPY_MODEL_388ac21acdd045fea5a62df55d73ec5e",
            "tabbable": null,
            "tooltip": null,
            "value": " 1239/1239 [00:00&lt;00:00, 17753.41 examples/s]"
          }
        },
        "0deb37ab07b4470d86834e7f0e14f3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "101f50ee24c549e59573aa5bac1d46c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a218d84ac074be3aa418fd358447edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_438453698b5a4e71b6d36cd462153448",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_101f50ee24c549e59573aa5bac1d46c0",
            "value": 11
          }
        },
        "1bba9d5e6fcf4328be37e2ef5c9370fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "284853260a2148bcbfbaba138abf995c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac3d00f60f542e99c0903fcd7e5b896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33dfda509e0d4893a1eb212f3fda1a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4e2626615b6844498abec6f75822bfd2",
            "placeholder": "​",
            "style": "IPY_MODEL_7355317cd4ec4ad3854257d6d73391a5",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "386d0945f93e46be90788aa0f90420ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388ac21acdd045fea5a62df55d73ec5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3cd9cf3ea2924602b12fbee631eb5d44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438453698b5a4e71b6d36cd462153448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44cf7f7db20e48febf521c6f7abebe5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_386d0945f93e46be90788aa0f90420ab",
            "placeholder": "​",
            "style": "IPY_MODEL_0deb37ab07b4470d86834e7f0e14f3e9",
            "value": " 11/11 [00:00&lt;00:00, 1352.64it/s]"
          }
        },
        "4c4a33470a224792b51a86540e6eceff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6f2ffe8a04f484ca3a01b00b69a483a",
              "IPY_MODEL_1a218d84ac074be3aa418fd358447edc",
              "IPY_MODEL_44cf7f7db20e48febf521c6f7abebe5d"
            ],
            "layout": "IPY_MODEL_284853260a2148bcbfbaba138abf995c"
          }
        },
        "4e2626615b6844498abec6f75822bfd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5244ef41bc1947f8b2e09269dc464f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "546cfd35dcbe4c6494cf0d87dd362c71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b14724e198040399f603fb07b6c6d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "6004f096640a4e41a005c5ef5bffa7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eed405af8934dc39eab95854354281e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9f47deb2f2e6474ea8b77e728ffbbf77",
            "placeholder": "​",
            "style": "IPY_MODEL_b3e7e510b4234d2a907d54336aa2f29f",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "7355317cd4ec4ad3854257d6d73391a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "78824336e49c44129a3d806cd5f05d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6004f096640a4e41a005c5ef5bffa7e7",
            "placeholder": "​",
            "style": "IPY_MODEL_ef00afa81c3e455a87518000206d2fba",
            "value": " 12/12 [00:00&lt;00:00, 1406.11it/s]"
          }
        },
        "7a82a2cbdf30473c95e1fb762fdfaa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aa28ae5670240ba9e24baade5daf6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860190e272954723bc22afe0d438fc10",
            "placeholder": "​",
            "style": "IPY_MODEL_f78ddb9354e0482ab922c873983f5c0f",
            "value": "Fetching 12 files: 100%"
          }
        },
        "860190e272954723bc22afe0d438fc10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8624942a65ec413e8246d7e2f813e3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2ac3d00f60f542e99c0903fcd7e5b896",
            "max": 5837,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a82a2cbdf30473c95e1fb762fdfaa23",
            "tabbable": null,
            "tooltip": null,
            "value": 5837
          }
        },
        "8b806f79844a4d01bacf3d448b0b158b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f34af8aed1c407ba1805f337c5d9228": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f47deb2f2e6474ea8b77e728ffbbf77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81e997ab37e4bb18e70d243079a0fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa80589f298e431eac10d7edba0c174b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7aa28ae5670240ba9e24baade5daf6fe",
              "IPY_MODEL_b8dc57580fa24f138f112e71130821ca",
              "IPY_MODEL_78824336e49c44129a3d806cd5f05d62"
            ],
            "layout": "IPY_MODEL_afae93401e354aaab13ffc5dff0d0487"
          }
        },
        "ae4775a13ca446da9c99d102038fbac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1bba9d5e6fcf4328be37e2ef5c9370fe",
            "placeholder": "​",
            "style": "IPY_MODEL_5b14724e198040399f603fb07b6c6d69",
            "tabbable": null,
            "tooltip": null,
            "value": " 5837/5837 [00:00&lt;00:00, 23251.59 examples/s]"
          }
        },
        "afae93401e354aaab13ffc5dff0d0487": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e4110ea0b84bca9434fe2c72f90543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6eed405af8934dc39eab95854354281e",
              "IPY_MODEL_8624942a65ec413e8246d7e2f813e3d2",
              "IPY_MODEL_ae4775a13ca446da9c99d102038fbac5"
            ],
            "layout": "IPY_MODEL_9f34af8aed1c407ba1805f337c5d9228",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b3e7e510b4234d2a907d54336aa2f29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b6f2ffe8a04f484ca3a01b00b69a483a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cd9cf3ea2924602b12fbee631eb5d44",
            "placeholder": "​",
            "style": "IPY_MODEL_080edebc63e145d1baac0b0af8d71689",
            "value": "Fetching 11 files: 100%"
          }
        },
        "b8dc57580fa24f138f112e71130821ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546cfd35dcbe4c6494cf0d87dd362c71",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5244ef41bc1947f8b2e09269dc464f58",
            "value": 12
          }
        },
        "bc6f34e10ed6465587cc16ab9309b523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef00afa81c3e455a87518000206d2fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0f6551654ef44aabdc8f7b11243095d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33dfda509e0d4893a1eb212f3fda1a69",
              "IPY_MODEL_0567107daa1a4e88984b9ba55458131e",
              "IPY_MODEL_08cda4f5a3dd4b3db9b624cb2e7e1103"
            ],
            "layout": "IPY_MODEL_bc6f34e10ed6465587cc16ab9309b523",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f78ddb9354e0482ab922c873983f5c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
