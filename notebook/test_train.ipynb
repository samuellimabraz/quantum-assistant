{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "bzhvqhuvCknH"
      },
      "id": "bzhvqhuvCknH"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q qwen_vl_utils decord librosa icecream"
      ],
      "metadata": {
        "id": "Fvij4u6oOS0O",
        "collapsed": true
      },
      "id": "Fvij4u6oOS0O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir ms-swift -U"
      ],
      "metadata": {
        "id": "pE0krTTTOap4",
        "collapsed": true
      },
      "id": "pE0krTTTOap4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.57.0"
      ],
      "metadata": {
        "id": "PA8UcUZ231ky"
      },
      "id": "PA8UcUZ231ky",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show unsloth"
      ],
      "metadata": {
        "id": "BqW_M5fqwLs8"
      },
      "id": "BqW_M5fqwLs8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show ms-swift\n",
        "!pip show transformers\n",
        "!pip show flash-attn\n",
        "!pip show torch\n",
        "!pip show deepspeed\n",
        "!pip show liger-kernel\n",
        "!pip show hf_transfer\n",
        "!pip show qwen_vl_utils\n",
        "!pip show decord\n",
        "!pip show librosa"
      ],
      "metadata": {
        "id": "_rhublm-YExe"
      },
      "id": "_rhublm-YExe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "DM6YDy5xCrPM"
      },
      "id": "DM6YDy5xCrPM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Hugging Face Hub**"
      ],
      "metadata": {
        "id": "V94pqTn9OBd6"
      },
      "id": "V94pqTn9OBd6"
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "login(token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "IHxVGs4aNySr"
      },
      "id": "IHxVGs4aNySr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVzSyeT3nmO"
      },
      "source": [
        "#### Free Memory"
      ],
      "id": "qjVzSyeT3nmO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLhS1pKQ3po1"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "import time\n",
        "\n",
        "def flush():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  torch.cuda.reset_peak_memory_stats()\n",
        "  for _ in range(10):\n",
        "        gc.collect()\n",
        "        with torch.no_grad():\n",
        "          torch.cuda.empty_cache()\n",
        "        time.sleep(0.1)"
      ],
      "id": "VLhS1pKQ3po1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "W4j7BS4_N8tI"
      },
      "id": "W4j7BS4_N8tI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8935af4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8935af4f",
        "outputId": "c6b79f05-a859-4fe4-f864-dfbaac28265e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec  7 21:40:12 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   35C    P0             56W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be87bed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1be87bed",
        "outputId": "0ad249af-de3f-4da8-e90c-8de00f659934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/quantum-assistant\n"
          ]
        }
      ],
      "source": [
        "%cd quantum-assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487be3ea",
      "metadata": {
        "id": "487be3ea"
      },
      "outputs": [],
      "source": [
        "!git switch dev\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "R-zozEu-Tj9m"
      },
      "id": "R-zozEu-Tj9m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/huggingface/xet-core/refs/heads/main/git_xet/install.sh | sh\n",
        "!git xet install"
      ],
      "metadata": {
        "id": "mPnvpgCWFcsK"
      },
      "id": "mPnvpgCWFcsK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "7koV-BTuHbbR"
      },
      "id": "7koV-BTuHbbR"
    },
    {
      "cell_type": "code",
      "source": [
        "!finetune prepare --hub-id samuellimabraz/quantum-assistant --output-dir /content/swift_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s9U_AtcHgOL",
        "outputId": "42eb34fc-3a8c-437e-e02a-872e988fe21c"
      },
      "id": "2s9U_AtcHgOL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m╭──────────────────────────────╮\u001b[0m\n",
            "\u001b[36m│\u001b[0m \u001b[1;36mms-swift Dataset Preparation\u001b[0m \u001b[36m│\u001b[0m\n",
            "\u001b[36m╰──────────────────────────────╯\u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mDataset (Hub)   \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32msamuellimabraz/quantum-assistant\u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mOutput directory\u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32m/content/swift_data             \u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mImage max size  \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32m640                             \u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mImage format    \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32mJPEG                            \u001b[0m\u001b[32m \u001b[0m\n",
            "\u001b[2m \u001b[0m\u001b[2mSystem prompt   \u001b[0m\u001b[2m \u001b[0m\u001b[32m \u001b[0m\u001b[32mYes                             \u001b[0m\u001b[32m \u001b[0m\n",
            "\n",
            "Loading dataset from HuggingFace Hub: samuellimabraz/quantum-assistant\n",
            "README.md: 100% 767/767 [00:00<00:00, 7.07MB/s]\n",
            "data/train-00000-of-00001.parquet: 100% 222M/222M [00:01<00:00, 136MB/s]\n",
            "data/validation-00000-of-00001.parquet: 100% 45.9M/45.9M [00:00<00:00, 64.2MB/s]\n",
            "data/test-00000-of-00001.parquet: 100% 50.9M/50.9M [00:00<00:00, 98.2MB/s]\n",
            "Generating train split: 100% 5837/5837 [00:00<00:00, 13311.73 examples/s]\n",
            "Generating validation split: 100% 1239/1239 [00:00<00:00, 14562.09 examples/s]\n",
            "Generating test split: 100% 1290/1290 [00:00<00:00, 18953.62 examples/s]\n",
            "\n",
            "Processing train split (5837 samples)\n",
            "  train: 100% 5837/5837 [01:16<00:00, 75.97it/s] \n",
            "\n",
            "Processing validation split (1239 samples)\n",
            "  validation: 100% 1239/1239 [00:16<00:00, 74.99it/s]\n",
            "\n",
            "Processing test split (1290 samples)\n",
            "  test: 100% 1290/1290 [00:17<00:00, 73.63it/s] \n",
            "\n",
            "Summary saved to /content/swift_data/summary.json\n",
            "Total images processed: 2932\n",
            "\u001b[32m╭──────────────────────╮\u001b[0m\n",
            "\u001b[32m│\u001b[0m \u001b[1;32mPreparation Complete\u001b[0m \u001b[32m│\u001b[0m\n",
            "\u001b[32m╰──────────────────────╯\u001b[0m\n",
            "\u001b[3m                         Results by Split                         \u001b[0m\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mSplit     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTotal\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMultimodal\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mText-only\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36mtrain     \u001b[0m\u001b[36m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mtrain.jsonl     \u001b[0m\u001b[2m \u001b[0m│  5837 │\u001b[33m \u001b[0m\u001b[33m      2633\u001b[0m\u001b[33m \u001b[0m│      3204 │\n",
            "│\u001b[36m \u001b[0m\u001b[36mvalidation\u001b[0m\u001b[36m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mvalidation.jsonl\u001b[0m\u001b[2m \u001b[0m│  1239 │\u001b[33m \u001b[0m\u001b[33m       560\u001b[0m\u001b[33m \u001b[0m│       679 │\n",
            "│\u001b[36m \u001b[0m\u001b[36mtest      \u001b[0m\u001b[36m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mtest.jsonl      \u001b[0m\u001b[2m \u001b[0m│  1290 │\u001b[33m \u001b[0m\u001b[33m       581\u001b[0m\u001b[33m \u001b[0m│       709 │\n",
            "└────────────┴──────────────────┴───────┴────────────┴───────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ba8d08",
      "metadata": {
        "id": "99ba8d08"
      },
      "source": [
        "## SwiftSft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "3U3Nt-CWMF_u"
      },
      "id": "3U3Nt-CWMF_u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['USE_HF'] = '1'\n",
        "os.environ['MAX_PIXELS'] = str(1280 * 28 * 28)\n",
        "\n",
        "\n",
        "from swift.utils import get_logger, get_model_parameter_info, plot_images, seed_everything\n",
        "from swift.llm.train.sft import SwiftSft\n",
        "from swift.llm import TrainArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "logger = get_logger()\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFWaW9XAHBox",
        "outputId": "5bfe1ab2-fcc3-4e7f-dda1-779a8a6b802e"
      },
      "id": "iFWaW9XAHBox",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO:swift] Successfully registered `/usr/local/lib/python3.12/dist-packages/swift/llm/dataset/data/dataset_info.json`.\n",
            "[INFO:swift] Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwEsA3lqVH2S",
        "outputId": "e923876e-8381-4fe7-c82b-124bc63ab523"
      },
      "id": "OwEsA3lqVH2S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3679aa47",
      "metadata": {
        "id": "3679aa47"
      },
      "outputs": [],
      "source": [
        "model_id_or_path = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
        "model_name = model_id_or_path.split('/')[-1] + '-r8-rslora-bf16-tuned'\n",
        "output_dir = os.path.join(os.getcwd(), \"train\", model_name)\n",
        "\n",
        "logger.info(f'output_dir: {output_dir}')\n",
        "\n",
        "args = TrainArguments(\n",
        "    model=model_id_or_path,\n",
        "    model_name = model_name,\n",
        "    model_author=\"samuellimabraz\",\n",
        "    dataset=['/content/swift_data/train.jsonl'],\n",
        "    val_dataset=['/content/swift_data/validation.jsonl'],\n",
        "    load_from_cache_file=True,\n",
        "    torch_dtype='bfloat16',\n",
        "    max_pixels=1280 * 28 * 28,\n",
        "    attn_impl='flash_attn', #'sdpa'\n",
        "    padding_side='left',\n",
        "    padding_free=True,\n",
        "    # packing=True,\n",
        "    lazy_tokenize=False,\n",
        "    #max_length=8192,\n",
        "    max_new_tokens=4096,\n",
        "    temperature=0.,\n",
        "\n",
        "    # LoRA\n",
        "    train_type='lora',\n",
        "    lora_rank=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules='all-linear',\n",
        "    init_weights='true',\n",
        "    use_rslora=True,\n",
        "    freeze_llm=False,\n",
        "    freeze_vit=True,\n",
        "    freeze_aligner=True,\n",
        "\n",
        "    # Train\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=2e-4,\n",
        "    #auto_find_batch_size=True,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        "    torch_empty_cache_steps = 50,\n",
        "    gradient_checkpointing=True,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps = 10,\n",
        "    warmup_ratio=0.05,\n",
        "    num_train_epochs=1,\n",
        "    lr_scheduler_type='cosine',\n",
        "    optim = \"adamw_torch\",\n",
        "    # neftune_noise_alpha=10,\n",
        "    logging_first_step=True,\n",
        "    logging_steps=5,\n",
        "    logging_strategy=\"steps\",\n",
        "    fp16 = not torch.cuda.is_bf16_supported(),\n",
        "    bf16 = torch.cuda.is_bf16_supported(),\n",
        "\n",
        "    # Eval\n",
        "    fp16_full_eval = True,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    eval_accumulation_steps = 4,\n",
        "    eval_strategy = \"steps\",\n",
        "    eval_steps = 20,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    save_strategy='best',\n",
        "    save_total_limit=5,\n",
        "    dataloader_num_workers=4,\n",
        "    remove_unused_columns=False,\n",
        "    data_seed=42,\n",
        "    report_to=[\"wandb\", \"tensorboard\"],\n",
        "\n",
        "    use_hf=True,\n",
        "    push_to_hub=True,\n",
        "    hub_private_repo=True,\n",
        "    hub_strategy=\"end\",\n",
        "    hub_model_id=f\"samuellimabraz/{model_name}\",\n",
        "    project=\"quantum-assistant\",\n",
        "    run_name=model_name\n",
        ")\n",
        "sft = SwiftSft(args)\n",
        "sft.callbacks.append(\n",
        "    EarlyStoppingCallback(\n",
        "        early_stopping_patience=5,\n",
        "        early_stopping_threshold=0.001\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_PROJECT\"] = \"quantum-assistant\""
      ],
      "metadata": {
        "id": "M5gaqSTCJ2MZ"
      },
      "id": "M5gaqSTCJ2MZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sft.main()"
      ],
      "metadata": {
        "id": "xBwf_r49M7PD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b0e4110ea0b84bca9434fe2c72f90543",
            "6eed405af8934dc39eab95854354281e",
            "8624942a65ec413e8246d7e2f813e3d2",
            "ae4775a13ca446da9c99d102038fbac5",
            "9f34af8aed1c407ba1805f337c5d9228",
            "9f47deb2f2e6474ea8b77e728ffbbf77",
            "b3e7e510b4234d2a907d54336aa2f29f",
            "2ac3d00f60f542e99c0903fcd7e5b896",
            "7a82a2cbdf30473c95e1fb762fdfaa23",
            "1bba9d5e6fcf4328be37e2ef5c9370fe",
            "5b14724e198040399f603fb07b6c6d69",
            "f0f6551654ef44aabdc8f7b11243095d",
            "33dfda509e0d4893a1eb212f3fda1a69",
            "0567107daa1a4e88984b9ba55458131e",
            "08cda4f5a3dd4b3db9b624cb2e7e1103",
            "bc6f34e10ed6465587cc16ab9309b523",
            "4e2626615b6844498abec6f75822bfd2",
            "7355317cd4ec4ad3854257d6d73391a5",
            "a81e997ab37e4bb18e70d243079a0fbd",
            "07d8ada74dab4b8695670d46c3ac72df",
            "8b806f79844a4d01bacf3d448b0b158b",
            "388ac21acdd045fea5a62df55d73ec5e"
          ]
        },
        "outputId": "648c4cdd-f591-4e27-d1e3-1391696d0712"
      },
      "id": "xBwf_r49M7PD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO:swift] Start time of running main: 2025-12-07 18:57:35.248979\n",
            "[INFO:swift] swift.__version__: 3.10.3\n",
            "[INFO:swift] SelfCognitionPreprocessor has been successfully configured with name: ('Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned', 'Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned'), author: ('samuellimabraz', 'samuellimabraz').\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5837 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0e4110ea0b84bca9434fe2c72f90543"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1239 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0f6551654ef44aabdc8f7b11243095d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO:swift] train_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 5837\n",
            "})\n",
            "[INFO:swift] val_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 1239\n",
            "})\n",
            "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 30128, 24231, 6203, 17847, 57294, 304, 1207, 3187, 275, 13, 39565, 13382, 11, 2797, 11, 323, 1632, 12, 51143, 14507, 911, 30128, 24231, 18940, 11, 25185, 11, 323, 2038, 8129, 13, 5443, 1207, 3187, 275, 220, 17, 13, 15, 1850, 12378, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 198, 4021, 279, 30128, 16224, 43794, 304, 279, 2168, 25, 264, 220, 18, 55964, 80, 59220, 16224, 1380, 264, 23864, 309, 567, 18126, 374, 9251, 311, 2804, 59220, 378, 107, 17, 11, 8110, 553, 264, 356, 14065, 448, 2524, 378, 107, 17, 323, 2169, 378, 107, 16, 11, 264, 13387, 2537, 1948, 2804, 81402, 378, 107, 15, 323, 378, 107, 16, 11, 323, 2441, 356, 14065, 448, 2524, 378, 107, 17, 323, 2169, 378, 107, 16, 13, 1446, 1969, 4211, 419, 1667, 264, 729, 6941, 1565, 5834, 1523, 40991, 666, 87, 666, 37268, 63, 448, 902, 5977, 13, 151645, 198, 151644, 77091, 198, 1499, 2804, 3187, 275, 1159, 55313, 34, 37268, 271, 750, 1936, 1523, 40991, 666, 87, 666, 37268, 3932, 262, 77066, 284, 55313, 34, 37268, 7, 18, 340, 262, 77066, 860, 7, 17, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 77066, 54537, 7, 15, 11, 220, 16, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [INPUT] <|im_start|>system\n",
            "You are a quantum computing expert assistant specializing in Qiskit. Provide accurate, clear, and well-structured responses about quantum computing concepts, algorithms, and code implementation. Use Qiskit 2.0 best practices.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|vision_start|>[151655 * 77]<|vision_end|>\n",
            "Create the quantum circuit depicted in the image: a 3‑qubit circuit where a Hadamard gate is applied to qubit 2, followed by a CNOT with control 2 and target 1, a SWAP between qubits 0 and 1, and another CNOT with control 2 and target 1. You must implement this using a function named `build_h_swap_cx_circuit` with no arguments.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "from qiskit import QuantumCircuit\n",
            "\n",
            "def build_h_swap_cx_circuit():\n",
            "    qc = QuantumCircuit(3)\n",
            "    qc.h(2)\n",
            "    qc.cx(2, 1)\n",
            "    qc.swap(0, 1)\n",
            "    qc.cx(2, 1)\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1499, 2804, 3187, 275, 1159, 55313, 34, 37268, 271, 750, 1936, 1523, 40991, 666, 87, 666, 37268, 3932, 262, 77066, 284, 55313, 34, 37268, 7, 18, 340, 262, 77066, 860, 7, 17, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 77066, 54537, 7, 15, 11, 220, 16, 340, 262, 77066, 69074, 7, 17, 11, 220, 16, 340, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [LABELS] [-100 * 235]from qiskit import QuantumCircuit\n",
            "\n",
            "def build_h_swap_cx_circuit():\n",
            "    qc = QuantumCircuit(3)\n",
            "    qc.h(2)\n",
            "    qc.cx(2, 1)\n",
            "    qc.swap(0, 1)\n",
            "    qc.cx(2, 1)\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] The TrainArguments will be saved in: /content/train/Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned/v0-20251207-185719/args.json\n",
            "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-4B-Instruct/snapshots/ebb281ec70b05090aa6165b016eac8ec08e71b17', revision=None, inference_mode=False, r=8, target_modules='^(model.language_model.*\\\\.(gate_proj|up_proj|k_proj|v_proj|down_proj|q_proj|o_proj))$', exclude_modules=None, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=True, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
            "[INFO:swift] model: PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): Qwen3VLForConditionalGeneration(\n",
            "      (model): Qwen3VLModel(\n",
            "        (visual): Qwen3VLVisionModel(\n",
            "          (patch_embed): Qwen3VLVisionPatchEmbed(\n",
            "            (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
            "          )\n",
            "          (pos_embed): Embedding(2304, 1024)\n",
            "          (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
            "          (blocks): ModuleList(\n",
            "            (0-23): 24 x Qwen3VLVisionBlock(\n",
            "              (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (attn): Qwen3VLVisionAttention(\n",
            "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              )\n",
            "              (mlp): Qwen3VLVisionMLP(\n",
            "                (linear_fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (linear_fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (act_fn): GELUTanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (merger): Qwen3VLVisionPatchMerger(\n",
            "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "            (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "            (act_fn): GELU(approximate='none')\n",
            "            (linear_fc2): Linear(in_features=4096, out_features=2560, bias=True)\n",
            "          )\n",
            "          (deepstack_merger_list): ModuleList(\n",
            "            (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
            "              (norm): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
            "              (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "              (act_fn): GELU(approximate='none')\n",
            "              (linear_fc2): Linear(in_features=4096, out_features=2560, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (language_model): Qwen3VLTextModel(\n",
            "          (embed_tokens): Embedding(151936, 2560)\n",
            "          (layers): ModuleList(\n",
            "            (0-35): 36 x Qwen3VLTextDecoderLayer(\n",
            "              (self_attn): Qwen3VLTextAttention(\n",
            "                (q_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=4096, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=4096, out_features=2560, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "              )\n",
            "              (mlp): Qwen3VLTextMLP(\n",
            "                (gate_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=9728, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (up_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=9728, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (down_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=9728, out_features=2560, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=9728, out_features=8, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (act_fn): SiLUActivation()\n",
            "              )\n",
            "              (input_layernorm): Qwen3VLTextRMSNorm((2560,), eps=1e-06)\n",
            "              (post_attention_layernorm): Qwen3VLTextRMSNorm((2560,), eps=1e-06)\n",
            "            )\n",
            "          )\n",
            "          (norm): Qwen3VLTextRMSNorm((2560,), eps=1e-06)\n",
            "          (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
            "        )\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 4454.3309M Params (16.5151M Trainable [0.3708%]), 0.0001M Buffers.\n",
            "[INFO:swift] use_reentrant: True\n",
            "[INFO:swift] The logging file will be saved in: /content/train/Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned/v0-20251207-185719/logging.jsonl\n",
            "[INFO:swift] Successfully registered post_encode hook: ['PeftModelForCausalLM'].\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None}.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamuellimabraz\u001b[0m (\u001b[33mblackbee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251207_185740-1y5nrdbs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/blackbee/quantum-assistant/runs/1y5nrdbs' target=\"_blank\">Qwen3-VL-4B-Instruct-r4-rslora-bf16-tuned</a></strong> to <a href='https://wandb.ai/blackbee/quantum-assistant' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/blackbee/quantum-assistant' target=\"_blank\">https://wandb.ai/blackbee/quantum-assistant</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/blackbee/quantum-assistant/runs/1y5nrdbs' target=\"_blank\">https://wandb.ai/blackbee/quantum-assistant/runs/1y5nrdbs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   0%|          | 0/366 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: False\n",
            "Train:   0%|          | 1/366 [01:05<6:35:27, 65.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.47564614, 'grad_norm': 3.08612037, 'learning_rate': 2e-05, 'token_acc': 0.75079031, 'epoch': 0.01, 'global_step/max_steps': '1/366', 'percentage': '0.27%', 'elapsed_time': '1m 5s', 'remaining_time': '6h 35m 29s', 'memory(GiB)': 32.71, 'train_speed(iter/s)': 0.015382}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   1%|          | 2/366 [01:52<5:31:39, 54.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.64435577, 'grad_norm': 2.97596097, 'learning_rate': 4e-05, 'token_acc': 0.7217824, 'epoch': 0.01, 'global_step/max_steps': '2/366', 'percentage': '0.55%', 'elapsed_time': '1m 52s', 'remaining_time': '5h 41m 4s', 'memory(GiB)': 36.85, 'train_speed(iter/s)': 0.017787}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   1%|          | 3/366 [03:02<6:14:36, 61.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.37458622, 'grad_norm': 2.69652987, 'learning_rate': 6e-05, 'token_acc': 0.75743661, 'epoch': 0.02, 'global_step/max_steps': '3/366', 'percentage': '0.82%', 'elapsed_time': '3m 2s', 'remaining_time': '6h 9m 1s', 'memory(GiB)': 60.25, 'train_speed(iter/s)': 0.016395}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   1%|          | 4/366 [04:03<6:10:46, 61.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.22692871, 'grad_norm': 2.56138492, 'learning_rate': 8e-05, 'token_acc': 0.77798551, 'epoch': 0.02, 'global_step/max_steps': '4/366', 'percentage': '1.09%', 'elapsed_time': '4m 3s', 'remaining_time': '6h 7m 37s', 'memory(GiB)': 60.25, 'train_speed(iter/s)': 0.016411}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   1%|▏         | 5/366 [05:27<6:57:23, 69.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.22136486, 'grad_norm': 1.9648397, 'learning_rate': 0.0001, 'token_acc': 0.74672152, 'epoch': 0.03, 'global_step/max_steps': '5/366', 'percentage': '1.37%', 'elapsed_time': '5m 27s', 'remaining_time': '6h 33m 39s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.015284}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 6/366 [06:45<7:14:56, 72.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.15417612, 'grad_norm': 2.03546643, 'learning_rate': 0.00012, 'token_acc': 0.76683697, 'epoch': 0.03, 'global_step/max_steps': '6/366', 'percentage': '1.64%', 'elapsed_time': '6m 45s', 'remaining_time': '6h 45m 41s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.01479}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 7/366 [08:03<7:24:16, 74.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.19977474, 'grad_norm': 1.48850739, 'learning_rate': 0.00014, 'token_acc': 0.73864521, 'epoch': 0.04, 'global_step/max_steps': '7/366', 'percentage': '1.91%', 'elapsed_time': '8m 3s', 'remaining_time': '6h 53m 20s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.014476}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 8/366 [09:33<7:53:02, 79.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.14413464, 'grad_norm': 0.84120828, 'learning_rate': 0.00016, 'token_acc': 0.73426408, 'epoch': 0.04, 'global_step/max_steps': '8/366', 'percentage': '2.19%', 'elapsed_time': '9m 33s', 'remaining_time': '7h 7m 49s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.013947}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 9/366 [11:46<9:30:51, 95.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.07826519, 'grad_norm': 0.69512147, 'learning_rate': 0.00018, 'token_acc': 0.72084548, 'epoch': 0.05, 'global_step/max_steps': '9/366', 'percentage': '2.46%', 'elapsed_time': '11m 46s', 'remaining_time': '7h 46m 52s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.012744}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   3%|▎         | 10/366 [12:20<7:36:42, 76.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.0660578, 'grad_norm': 0.67294222, 'learning_rate': 0.0002, 'token_acc': 0.74028668, 'epoch': 0.05, 'global_step/max_steps': '10/366', 'percentage': '2.73%', 'elapsed_time': '12m 20s', 'remaining_time': '7h 19m 28s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.013501}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   3%|▎         | 11/366 [14:17<8:47:54, 89.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.12724876, 'grad_norm': 0.87927151, 'learning_rate': 0.0002, 'token_acc': 0.71587938, 'epoch': 0.06, 'global_step/max_steps': '11/366', 'percentage': '3.01%', 'elapsed_time': '14m 17s', 'remaining_time': '7h 41m 19s', 'memory(GiB)': 74.27, 'train_speed(iter/s)': 0.012825}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' \\\n",
        "IMAGE_MAX_TOKEN_NUM=1024 \\\n",
        "CUDA_VISIBLE_DEVICES=0 \\\n",
        "swift sft \\\n",
        "    --model Qwen/Qwen3-VL-4B-Instruct \\\n",
        "    --dataset '/content/swift_data/train.jsonl' \\\n",
        "    --val_dataset '/content/swift_data/validation.jsonl' \\\n",
        "    --load_from_cache_file true \\\n",
        "    --train_type lora \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --attn_impl sdpa \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --lr_scheduler_type cosine \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --target_modules all-linear \\\n",
        "    --freeze_vit true \\\n",
        "    --freeze_aligner false \\\n",
        "    --gradient_checkpointing true \\\n",
        "    --vit_gradient_checkpointing false \\\n",
        "    --gradient_accumulation_steps 2 \\\n",
        "    --eval_steps 100 \\\n",
        "    --save_steps 100 \\\n",
        "    --save_total_limit 2 \\\n",
        "    --logging_steps 5 \\\n",
        "    --output_dir output \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --dataset_num_proc 4 \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --report_to tensorboard wandb \\\n",
        "    --use_hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBnzwRegqrAf",
        "outputId": "36c388f5-ffab-4e42-d21f-60b2d345d98f"
      },
      "id": "vBnzwRegqrAf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run sh: `/usr/bin/python3 /usr/local/lib/python3.12/dist-packages/swift/cli/sft.py --model Qwen/Qwen3-VL-2B-Instruct --dataset /content/swift_data/train.jsonl --val_dataset /content/swift_data/validation.jsonl --load_from_cache_file true --train_type lora --torch_dtype bfloat16 --num_train_epochs 1 --per_device_train_batch_size 2 --per_device_eval_batch_size 2 --attn_impl sdpa --learning_rate 1e-4 --lora_rank 16 --lora_alpha 32 --target_modules all-linear --freeze_vit true --freeze_aligner true --gradient_checkpointing true --vit_gradient_checkpointing false --gradient_accumulation_steps 2 --eval_steps 100 --save_steps 100 --save_total_limit 2 --logging_steps 5 --max_length 4096 --output_dir output --warmup_ratio 0.05 --dataset_num_proc 4 --dataloader_num_workers 4 --report_to tensorboard wandb --use_hf`\n",
            "2025-12-05 08:47:35.663359: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 08:47:35.682878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764924455.705865   32787 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764924455.713459   32787 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764924455.733106   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764924455.733134   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764924455.733137   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764924455.733140   32787 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 08:47:35.738202: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO:swift] Successfully registered `/usr/local/lib/python3.12/dist-packages/swift/llm/dataset/data/dataset_info.json`.\n",
            "[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: Qwen/Qwen3-VL-2B-Instruct\n",
            "Fetching 11 files: 100% 11/11 [00:00<00:00, 32652.05it/s]\n",
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "[INFO:swift] Because len(args.val_dataset) > 0, setting split_dataset_ratio: 0.0\n",
            "[INFO:swift] Setting args.lazy_tokenize: True\n",
            "[INFO:swift] output_dir: /content/output/v0-20251205-084749\n",
            "[INFO:swift] Global seed set to 42\n",
            "[INFO:swift] args: TrainArguments(\n",
            "_n_gpu=-1,\n",
            "acc_strategy=token,\n",
            "accelerator_config={'dispatch_batches': False},\n",
            "adafactor=False,\n",
            "adalora_beta1=0.85,\n",
            "adalora_beta2=0.85,\n",
            "adalora_deltaT=1,\n",
            "adalora_init_r=12,\n",
            "adalora_orth_reg_weight=0.5,\n",
            "adalora_target_r=8,\n",
            "adalora_tfinal=0,\n",
            "adalora_tinit=0,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.95,\n",
            "adam_epsilon=1e-08,\n",
            "adapter_act=gelu,\n",
            "adapter_length=128,\n",
            "adapters=[],\n",
            "add_version=True,\n",
            "agent_template=None,\n",
            "aligner_lr=None,\n",
            "attn_impl=sdpa,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "bnb_4bit_compute_dtype=torch.bfloat16,\n",
            "bnb_4bit_quant_storage=None,\n",
            "bnb_4bit_quant_type=nf4,\n",
            "bnb_4bit_use_double_quant=True,\n",
            "boft_block_num=0,\n",
            "boft_block_size=4,\n",
            "boft_dropout=0.0,\n",
            "boft_n_butterfly_factor=1,\n",
            "cached_dataset=[],\n",
            "check_model=True,\n",
            "ckpt_dir=None,\n",
            "columns={},\n",
            "create_checkpoint_symlink=False,\n",
            "custom_dataset_info=[],\n",
            "custom_register_path=[],\n",
            "data_seed=42,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=4,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset=['/content/swift_data/train.jsonl'],\n",
            "dataset_num_proc=4,\n",
            "dataset_shuffle=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=18000000,\n",
            "debug=None,\n",
            "deepspeed=None,\n",
            "deepspeed_autotp_size=None,\n",
            "device_groups=None,\n",
            "device_map=None,\n",
            "disable_tqdm=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "download_mode=reuse_dataset_if_exists,\n",
            "ds3_gather_for_generation=True,\n",
            "early_stop_interval=None,\n",
            "enable_channel_loss=False,\n",
            "enable_dft_loss=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_dataset=[],\n",
            "eval_dataset_args=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_generation_config=None,\n",
            "eval_limit=None,\n",
            "eval_on_start=False,\n",
            "eval_steps=100.0,\n",
            "eval_strategy=steps,\n",
            "eval_use_evalscope=False,\n",
            "eval_use_gather_object=False,\n",
            "external_plugins=[],\n",
            "extra_eval_args=None,\n",
            "fourier_n_frequency=2000,\n",
            "fourier_scaling=300.0,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "freeze_aligner=True,\n",
            "freeze_llm=False,\n",
            "freeze_parameters=[],\n",
            "freeze_parameters_ratio=0.0,\n",
            "freeze_parameters_regex=None,\n",
            "freeze_vit=True,\n",
            "fsdp=None,\n",
            "fsdp_config=None,\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "galore_cos_threshold=0.4,\n",
            "galore_gamma_proj=2,\n",
            "galore_optim_per_parameter=False,\n",
            "galore_proj_bits=4,\n",
            "galore_proj_group_size=256,\n",
            "galore_proj_quant=False,\n",
            "galore_proj_type=std,\n",
            "galore_quantization=False,\n",
            "galore_queue_size=5,\n",
            "galore_rank=128,\n",
            "galore_scale=1.0,\n",
            "galore_target_modules=None,\n",
            "galore_update_proj_gap=50,\n",
            "galore_with_embedding=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hqq_axis=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_args_error=False,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "init_strategy=None,\n",
            "init_weights=True,\n",
            "interleave_prob=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "lazy_tokenize=True,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "lisa_activated_layers=0,\n",
            "lisa_step_interval=20,\n",
            "llamapro_num_groups=None,\n",
            "llamapro_num_new_blocks=4,\n",
            "load_args=False,\n",
            "load_best_model_at_end=False,\n",
            "load_data_args=False,\n",
            "load_from_cache_file=True,\n",
            "local_rank=-1,\n",
            "local_repo_path=None,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/output/v0-20251205-084749/runs,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5,\n",
            "logging_strategy=steps,\n",
            "logprobs=False,\n",
            "lora_alpha=32,\n",
            "lora_bias=none,\n",
            "lora_dropout=0.05,\n",
            "lora_dtype=None,\n",
            "lora_ga_batch_size=2,\n",
            "lora_ga_direction=ArB2r,\n",
            "lora_ga_iters=2,\n",
            "lora_ga_max_length=1024,\n",
            "lora_ga_scale=stable,\n",
            "lora_ga_stable_gamma=16,\n",
            "lora_modules=[],\n",
            "lora_rank=16,\n",
            "lorap_lr_ratio=None,\n",
            "loss_scale=default,\n",
            "loss_type=None,\n",
            "lr_scheduler_kwargs=None,\n",
            "lr_scheduler_type=cosine,\n",
            "max_epochs=None,\n",
            "max_grad_norm=1.0,\n",
            "max_length=4096,\n",
            "max_memory={},\n",
            "max_model_len=None,\n",
            "max_new_tokens=64,\n",
            "max_pixels=None,\n",
            "max_steps=-1,\n",
            "metric=None,\n",
            "metric_for_best_model=loss,\n",
            "model=Qwen/Qwen3-VL-2B-Instruct,\n",
            "model_author=None,\n",
            "model_kwargs={},\n",
            "model_name=None,\n",
            "model_revision=None,\n",
            "model_type=qwen3_vl,\n",
            "modules_to_save=[],\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "new_special_tokens=[],\n",
            "no_cuda=False,\n",
            "norm_bbox=None,\n",
            "num_beams=1,\n",
            "num_labels=None,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_torch_fused,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "optimizer=None,\n",
            "output_dir=/content/output/v0-20251205-084749,\n",
            "overwrite_output_dir=False,\n",
            "packing=False,\n",
            "packing_length=None,\n",
            "padding_free=False,\n",
            "padding_side=right,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=2,\n",
            "per_device_train_batch_size=2,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "problem_type=None,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "quant_bits=None,\n",
            "quant_method=None,\n",
            "ray_exp_name=None,\n",
            "ray_scope=last,\n",
            "reft_args=None,\n",
            "reft_intervention_type=LoreftIntervention,\n",
            "reft_layer_key=None,\n",
            "reft_layers=None,\n",
            "reft_rank=4,\n",
            "remove_unused_columns=True,\n",
            "repetition_penalty=None,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "response_prefix=None,\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "resume_only_model=False,\n",
            "rope_scaling=None,\n",
            "router_aux_loss_coef=0.0,\n",
            "run_name=/content/output/v0-20251205-084749,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=100.0,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "sequence_parallel_size=1,\n",
            "shuffle_buffer_size=1000,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_dataset_ratio=0.0,\n",
            "stop_words=[],\n",
            "stopping_strategy=first_exhausted,\n",
            "stream=False,\n",
            "streaming=False,\n",
            "strict=False,\n",
            "swanlab_exp_name=None,\n",
            "swanlab_lark_secret=None,\n",
            "swanlab_lark_webhook_url=None,\n",
            "swanlab_mode=cloud,\n",
            "swanlab_project=None,\n",
            "swanlab_token=<SWANLAB_TOKEN>,\n",
            "swanlab_workspace=None,\n",
            "system=None,\n",
            "target_modules=['all-linear'],\n",
            "target_parameters=None,\n",
            "target_regex=None,\n",
            "task_type=causal_lm,\n",
            "temperature=0.0,\n",
            "template=qwen3_vl,\n",
            "template_backend=swift,\n",
            "tf32=None,\n",
            "top_k=None,\n",
            "top_logprobs=None,\n",
            "top_p=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_dtype=torch.bfloat16,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "train_dataloader_shuffle=True,\n",
            "train_type=lora,\n",
            "trainable_parameters=[],\n",
            "trainable_parameters_regex=None,\n",
            "truncation_strategy=delete,\n",
            "tuner_backend=peft,\n",
            "use_chat_template=True,\n",
            "use_cpu=False,\n",
            "use_dora=False,\n",
            "use_flash_ckpt=False,\n",
            "use_galore=False,\n",
            "use_hf=True,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_logits_to_keep=None,\n",
            "use_mps_device=False,\n",
            "use_ray=False,\n",
            "use_rslora=False,\n",
            "use_swift_lora=False,\n",
            "val_dataset=['/content/swift_data/validation.jsonl'],\n",
            "val_dataset_shuffle=False,\n",
            "vera_d_initial=0.1,\n",
            "vera_dropout=0.0,\n",
            "vera_projection_prng_key=0,\n",
            "vera_rank=256,\n",
            "vit_gradient_checkpointing=False,\n",
            "vit_lr=None,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.1,\n",
            "zero_hpz_partition_size=None,\n",
            ")\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: Qwen/Qwen3-VL-2B-Instruct\n",
            "Fetching 12 files: 100% 12/12 [00:00<00:00, 19225.23it/s]\n",
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203\n",
            "[INFO:swift] attn_impl: sdpa\n",
            "[INFO:swift] model_kwargs: {'device_map': 'cuda:0', 'dtype': torch.bfloat16}\n",
            "[INFO:swift] Setting max_ratio: 200. You can adjust this hyperparameter through the environment variable: `MAX_RATIO`.\n",
            "[INFO:swift] Setting frame_factor: 2. You can adjust this hyperparameter through the environment variable: `FRAME_FACTOR`.\n",
            "[INFO:swift] Setting fps: 2.0. You can adjust this hyperparameter through the environment variable: `FPS`.\n",
            "[INFO:swift] Setting fps_min_frames: 4. You can adjust this hyperparameter through the environment variable: `FPS_MIN_FRAMES`.\n",
            "[INFO:swift] Setting fps_max_frames: 768. You can adjust this hyperparameter through the environment variable: `FPS_MAX_FRAMES`.\n",
            "[INFO:swift] Using environment variable `IMAGE_MAX_TOKEN_NUM`, Setting image_max_token_num: 1024.\n",
            "[INFO:swift] Setting image_min_token_num: 4. You can adjust this hyperparameter through the environment variable: `IMAGE_MIN_TOKEN_NUM`.\n",
            "[INFO:swift] Setting spatial_merge_size: 2. You can adjust this hyperparameter through the environment variable: `SPATIAL_MERGE_SIZE`.\n",
            "[INFO:swift] Setting video_max_token_num: 768. You can adjust this hyperparameter through the environment variable: `VIDEO_MAX_TOKEN_NUM`.\n",
            "[INFO:swift] Setting video_min_token_num: 128. You can adjust this hyperparameter through the environment variable: `VIDEO_MIN_TOKEN_NUM`.\n",
            "[INFO:swift] model.hf_device_map: {'': device(type='cuda', index=0)}\n",
            "[INFO:swift] model_info: ModelInfo(model_type='qwen3_vl', model_dir='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203', torch_dtype=torch.bfloat16, max_model_len=262144, quant_method=None, quant_bits=None, rope_scaling={'mrope_interleaved': True, 'mrope_section': [24, 20, 20], 'rope_type': 'default'}, is_moe_model=False, config=Qwen3VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"model_type\": \"qwen3_vl\",\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"text_config\": {\n",
            "    \"attention_bias\": false,\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bos_token_id\": 151643,\n",
            "    \"dtype\": \"bfloat16\",\n",
            "    \"eos_token_id\": 151645,\n",
            "    \"head_dim\": 128,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 2048,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 6144,\n",
            "    \"max_position_embeddings\": 262144,\n",
            "    \"model_type\": \"qwen3_vl_text\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_hidden_layers\": 28,\n",
            "    \"num_key_value_heads\": 8,\n",
            "    \"pad_token_id\": 151643,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": {\n",
            "      \"mrope_interleaved\": true,\n",
            "      \"mrope_section\": [\n",
            "        24,\n",
            "        20,\n",
            "        20\n",
            "      ],\n",
            "      \"rope_type\": \"default\"\n",
            "    },\n",
            "    \"rope_theta\": 5000000,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 151936\n",
            "  },\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"deepstack_visual_indexes\": [\n",
            "      5,\n",
            "      11,\n",
            "      17\n",
            "    ],\n",
            "    \"depth\": 24,\n",
            "    \"dtype\": \"bfloat16\",\n",
            "    \"hidden_act\": \"gelu_pytorch_tanh\",\n",
            "    \"hidden_size\": 1024,\n",
            "    \"in_channels\": 3,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 4096,\n",
            "    \"model_type\": \"qwen3_vl\",\n",
            "    \"num_heads\": 16,\n",
            "    \"num_position_embeddings\": 2304,\n",
            "    \"out_hidden_size\": 2048,\n",
            "    \"pad_token_id\": 151643,\n",
            "    \"patch_size\": 16,\n",
            "    \"spatial_merge_size\": 2,\n",
            "    \"temporal_patch_size\": 2\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652\n",
            "}\n",
            ", task_type='causal_lm', num_labels=None)\n",
            "[INFO:swift] model.generation_config: GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"max_new_tokens\": 64,\n",
            "  \"pad_token_id\": 151643\n",
            "}\n",
            "\n",
            "[INFO:swift] default_system: None\n",
            "[INFO:swift] max_length: 4096\n",
            "[INFO:swift] response_prefix: ''\n",
            "[INFO:swift] agent_template: hermes\n",
            "[INFO:swift] norm_bbox: norm1000\n",
            "[INFO:swift] Setting ROOT_IMAGE_DIR: None. You can adjust this hyperparameter through the environment variable: `ROOT_IMAGE_DIR`.\n",
            "[INFO:swift] Setting QWENVL_BBOX_FORMAT: legacy. You can adjust this hyperparameter through the environment variable: `QWENVL_BBOX_FORMAT`.\n",
            "[INFO:swift] Start time of running main: 2025-12-05 08:47:52.414560\n",
            "[INFO:swift] swift.__version__: 3.10.3\n",
            "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 65 examples [00:00, 19908.70 examples/s]\n",
            "Map (num_proc=4): 100% 65/65 [00:00<00:00, 384.81 examples/s]\n",
            "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 22 examples [00:00, 12019.63 examples/s]\n",
            "Map (num_proc=4): 100% 22/22 [00:00<00:00, 145.82 examples/s]\n",
            "[INFO:swift] train_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 65\n",
            "})\n",
            "[INFO:swift] val_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 22\n",
            "})\n",
            "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 30128, 24231, 6203, 17847, 57294, 304, 1207, 3187, 275, 13, 39565, 13382, 11, 2797, 11, 323, 1632, 12, 51143, 14507, 911, 30128, 24231, 18940, 11, 25185, 11, 323, 2038, 8129, 13, 5443, 1207, 3187, 275, 220, 17, 13, 15, 1850, 12378, 13, 151645, 198, 151644, 872, 198, 73594, 12669, 198, 1499, 2804, 3187, 275, 1159, 55313, 34, 37268, 198, 1499, 2804, 3187, 275, 520, 37268, 39285, 1159, 29288, 21807, 10060, 42318, 271, 750, 20908, 28043, 4178, 88, 666, 37268, 27978, 25, 2224, 11, 13440, 25, 2224, 284, 220, 15, 13, 15, 982, 262, 4210, 4021, 264, 220, 17, 55964, 80, 59220, 16224, 429, 16790, 458, 29288, 10, 10060, 16230, 448, 12695, 9210, 1565, 15976, 63, 323, 10262, 1565, 19127, 63, 14442, 262, 1494, 198, 73594, 151645, 198, 151644, 77091, 198, 59833, 284, 55313, 34, 37268, 7, 17, 340, 262, 18126, 284, 29288, 21807, 10060, 42318, 27978, 11, 13440, 340, 262, 77066, 2057, 3268, 349, 11, 508, 15, 11, 220, 16, 2546, 262, 77066, 2196, 58, 15, 936, 9262, 2644, 284, 330, 4146, 10, 4807, 698, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [INPUT] <|im_start|>system\n",
            "You are a quantum computing expert assistant specializing in Qiskit. Provide accurate, clear, and well-structured responses about quantum computing concepts, algorithms, and code implementation. Use Qiskit 2.0 best practices.<|im_end|>\n",
            "<|im_start|>user\n",
            "```python\n",
            "from qiskit import QuantumCircuit\n",
            "from qiskit.circuit.library import XXPlusYYGate\n",
            "\n",
            "def xx_plus_yy_circuit(theta: float, beta: float = 0.0):\n",
            "    \"\"\"Create a 2‑qubit circuit that applies an XX+YY interaction with rotation angle `theta` and phase `beta`.\"\"\"\n",
            "    pass\n",
            "```<|im_end|>\n",
            "<|im_start|>assistant\n",
            "qc = QuantumCircuit(2)\n",
            "    gate = XXPlusYYGate(theta, beta)\n",
            "    qc.append(gate, [0, 1])\n",
            "    qc.data[0].operation.name = \"xx+yy\"\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 59833, 284, 55313, 34, 37268, 7, 17, 340, 262, 18126, 284, 29288, 21807, 10060, 42318, 27978, 11, 13440, 340, 262, 77066, 2057, 3268, 349, 11, 508, 15, 11, 220, 16, 2546, 262, 77066, 2196, 58, 15, 936, 9262, 2644, 284, 330, 4146, 10, 4807, 698, 262, 470, 77066, 151645, 198]\n",
            "[INFO:swift] [LABELS] [-100 * 136]qc = QuantumCircuit(2)\n",
            "    gate = XXPlusYYGate(theta, beta)\n",
            "    qc.append(gate, [0, 1])\n",
            "    qc.data[0].operation.name = \"xx+yy\"\n",
            "    return qc<|im_end|>\n",
            "\n",
            "[INFO:swift] The TrainArguments will be saved in: /content/output/v0-20251205-084749/args.json\n",
            "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/root/.cache/huggingface/hub/models--Qwen--Qwen3-VL-2B-Instruct/snapshots/89644892e4d85e24eaac8bacfd4f463576704203', revision=None, inference_mode=False, r=16, target_modules='^(model.language_model.*\\\\.(gate_proj|down_proj|q_proj|o_proj|v_proj|up_proj|k_proj))$', exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
            "[INFO:swift] model: PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): Qwen3VLForConditionalGeneration(\n",
            "      (model): Qwen3VLModel(\n",
            "        (visual): Qwen3VLVisionModel(\n",
            "          (patch_embed): Qwen3VLVisionPatchEmbed(\n",
            "            (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
            "          )\n",
            "          (pos_embed): Embedding(2304, 1024)\n",
            "          (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
            "          (blocks): ModuleList(\n",
            "            (0-23): 24 x Qwen3VLVisionBlock(\n",
            "              (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "              (attn): Qwen3VLVisionAttention(\n",
            "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
            "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              )\n",
            "              (mlp): Qwen3VLVisionMLP(\n",
            "                (linear_fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "                (linear_fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "                (act_fn): GELUTanh()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (merger): Qwen3VLVisionPatchMerger(\n",
            "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
            "            (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "            (act_fn): GELU(approximate='none')\n",
            "            (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "          )\n",
            "          (deepstack_merger_list): ModuleList(\n",
            "            (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
            "              (norm): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
            "              (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "              (act_fn): GELU(approximate='none')\n",
            "              (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (language_model): Qwen3VLTextModel(\n",
            "          (embed_tokens): Embedding(151936, 2048)\n",
            "          (layers): ModuleList(\n",
            "            (0-27): 28 x Qwen3VLTextDecoderLayer(\n",
            "              (self_attn): Qwen3VLTextAttention(\n",
            "                (q_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
            "              )\n",
            "              (mlp): Qwen3VLTextMLP(\n",
            "                (gate_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=6144, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=6144, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (up_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=2048, out_features=6144, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=6144, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (down_proj): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=6144, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=6144, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (act_fn): SiLUActivation()\n",
            "              )\n",
            "              (input_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
            "              (post_attention_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
            "            )\n",
            "          )\n",
            "          (norm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
            "          (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
            "        )\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 2144.9646M Params (17.4326M Trainable [0.8127%]), 0.0001M Buffers.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "[INFO:swift] use_reentrant: True\n",
            "[INFO:swift] The logging file will be saved in: /content/output/v0-20251205-084749/logging.jsonl\n",
            "[INFO:swift] Successfully registered post_encode hook: ['PeftModelForCausalLM'].\n",
            "[WARNING:swift] prepare gradient_checkpointing failed: 'Qwen3VLVisionModel' object has no attribute '_require_grads_hook'\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 151645, 'bos_token_id': None}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamuellimabraz\u001b[0m (\u001b[33mblackbee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m setting up run ug74pkm5 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251205_084758-ug74pkm5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/content/output/v0-20251205-084749\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/blackbee/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/blackbee/huggingface/runs/ug74pkm5\u001b[0m\n",
            "Train:   0% 0/17 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: False\n",
            "{'loss': 0.85970342, 'grad_norm': 1.90481687, 'learning_rate': 0.0001, 'token_acc': 0.81791908, 'epoch': 0.06, 'global_step/max_steps': '1/17', 'percentage': '5.88%', 'elapsed_time': '6s', 'remaining_time': '1m 44s', 'memory(GiB)': 8.47, 'train_speed(iter/s)': 0.153481}\n",
            "{'loss': 1.01663578, 'grad_norm': 1.80471671, 'learning_rate': 8.536e-05, 'token_acc': 0.77156975, 'epoch': 0.3, 'global_step/max_steps': '5/17', 'percentage': '29.41%', 'elapsed_time': '30s', 'remaining_time': '1m 12s', 'memory(GiB)': 8.5, 'train_speed(iter/s)': 0.165795}\n",
            "{'loss': 1.18291492, 'grad_norm': 1.50467765, 'learning_rate': 4.025e-05, 'token_acc': 0.74276673, 'epoch': 0.61, 'global_step/max_steps': '10/17', 'percentage': '58.82%', 'elapsed_time': '1m 16s', 'remaining_time': '53s', 'memory(GiB)': 8.5, 'train_speed(iter/s)': 0.130746}\n",
            "{'loss': 1.09067736, 'grad_norm': 1.15591311, 'learning_rate': 3.81e-06, 'token_acc': 0.71851852, 'epoch': 0.91, 'global_step/max_steps': '15/17', 'percentage': '88.24%', 'elapsed_time': '2m 12s', 'remaining_time': '17s', 'memory(GiB)': 8.51, 'train_speed(iter/s)': 0.113592}\n",
            "Train: 100% 17/17 [02:44<00:00, 11.77s/it]\n",
            "{'eval_loss': 0.90164608, 'eval_runtime': 53.3679, 'eval_samples_per_second': 0.412, 'eval_steps_per_second': 0.206, 'eval_token_acc': 0.77504052, 'epoch': 1.0, 'global_step/max_steps': '17/17', 'percentage': '100.00%', 'elapsed_time': '3m 38s', 'remaining_time': '0s', 'memory(GiB)': 8.51, 'train_speed(iter/s)': 0.077911}\n",
            "Val: 100% 11/11 [00:46<00:00,  4.20s/it]\n",
            "[INFO:swift] Saving model checkpoint to /content/output/v0-20251205-084749/checkpoint-17\n",
            "{'train_runtime': 221.5605, 'train_samples_per_second': 0.293, 'train_steps_per_second': 0.077, 'train_loss': 1.05035187, 'epoch': 1.0, 'global_step/max_steps': '17/17', 'percentage': '100.00%', 'elapsed_time': '3m 39s', 'remaining_time': '0s', 'memory(GiB)': 8.51, 'train_speed(iter/s)': 0.077502}\n",
            "Train: 100% 17/17 [03:39<00:00, 12.90s/it]\n",
            "[INFO:swift] last_model_checkpoint: /content/output/v0-20251205-084749/checkpoint-17\n",
            "[INFO:swift] best_model_checkpoint: /content/output/v0-20251205-084749/checkpoint-17\n",
            "[INFO:swift] images_dir: /content/output/v0-20251205-084749/images\n",
            "[INFO:swift] End time of running main: 2025-12-05 08:51:41.671839\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m/content/output/v0-20251205-084749\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251205_084758-ug74pkm5/logs\u001b[0m\n",
            "[W1205 08:51:45.502153709 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
            "[W1205 08:51:46.272114041 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "uXWvkohn9emo",
        "qjVzSyeT3nmO"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0e4110ea0b84bca9434fe2c72f90543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6eed405af8934dc39eab95854354281e",
              "IPY_MODEL_8624942a65ec413e8246d7e2f813e3d2",
              "IPY_MODEL_ae4775a13ca446da9c99d102038fbac5"
            ],
            "layout": "IPY_MODEL_9f34af8aed1c407ba1805f337c5d9228",
            "tabbable": null,
            "tooltip": null
          }
        },
        "6eed405af8934dc39eab95854354281e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9f47deb2f2e6474ea8b77e728ffbbf77",
            "placeholder": "​",
            "style": "IPY_MODEL_b3e7e510b4234d2a907d54336aa2f29f",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "8624942a65ec413e8246d7e2f813e3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2ac3d00f60f542e99c0903fcd7e5b896",
            "max": 5837,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a82a2cbdf30473c95e1fb762fdfaa23",
            "tabbable": null,
            "tooltip": null,
            "value": 5837
          }
        },
        "ae4775a13ca446da9c99d102038fbac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1bba9d5e6fcf4328be37e2ef5c9370fe",
            "placeholder": "​",
            "style": "IPY_MODEL_5b14724e198040399f603fb07b6c6d69",
            "tabbable": null,
            "tooltip": null,
            "value": " 5837/5837 [00:00&lt;00:00, 23251.59 examples/s]"
          }
        },
        "9f34af8aed1c407ba1805f337c5d9228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f47deb2f2e6474ea8b77e728ffbbf77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e7e510b4234d2a907d54336aa2f29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "2ac3d00f60f542e99c0903fcd7e5b896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a82a2cbdf30473c95e1fb762fdfaa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bba9d5e6fcf4328be37e2ef5c9370fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b14724e198040399f603fb07b6c6d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f0f6551654ef44aabdc8f7b11243095d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33dfda509e0d4893a1eb212f3fda1a69",
              "IPY_MODEL_0567107daa1a4e88984b9ba55458131e",
              "IPY_MODEL_08cda4f5a3dd4b3db9b624cb2e7e1103"
            ],
            "layout": "IPY_MODEL_bc6f34e10ed6465587cc16ab9309b523",
            "tabbable": null,
            "tooltip": null
          }
        },
        "33dfda509e0d4893a1eb212f3fda1a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4e2626615b6844498abec6f75822bfd2",
            "placeholder": "​",
            "style": "IPY_MODEL_7355317cd4ec4ad3854257d6d73391a5",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "0567107daa1a4e88984b9ba55458131e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a81e997ab37e4bb18e70d243079a0fbd",
            "max": 1239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07d8ada74dab4b8695670d46c3ac72df",
            "tabbable": null,
            "tooltip": null,
            "value": 1239
          }
        },
        "08cda4f5a3dd4b3db9b624cb2e7e1103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8b806f79844a4d01bacf3d448b0b158b",
            "placeholder": "​",
            "style": "IPY_MODEL_388ac21acdd045fea5a62df55d73ec5e",
            "tabbable": null,
            "tooltip": null,
            "value": " 1239/1239 [00:00&lt;00:00, 17753.41 examples/s]"
          }
        },
        "bc6f34e10ed6465587cc16ab9309b523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e2626615b6844498abec6f75822bfd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7355317cd4ec4ad3854257d6d73391a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a81e997ab37e4bb18e70d243079a0fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d8ada74dab4b8695670d46c3ac72df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b806f79844a4d01bacf3d448b0b158b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388ac21acdd045fea5a62df55d73ec5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}